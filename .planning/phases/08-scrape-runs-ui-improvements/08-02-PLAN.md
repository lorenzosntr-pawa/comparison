---
phase: 08-scrape-runs-ui-improvements
plan: 02
type: execute
---

<objective>
Add historical analytics showing scrape performance trends over time.

Purpose: Enable understanding of scraping health and patterns through duration trends, success rates, and event volume charts.
Output: Analytics section on Scrape Runs page with charts, backed by new API endpoint for aggregated data.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./08-02-SUMMARY.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-scrape-runs-ui-improvements/08-CONTEXT.md

# Prior plan in this phase:
@.planning/phases/08-scrape-runs-ui-improvements/08-01-SUMMARY.md

# Key files to understand:
@src/api/routes/scrape.py
@src/api/schemas/scheduler.py
@web/src/features/scrape-runs/index.tsx
@web/src/features/scrape-runs/components/stats-summary.tsx

**Tech stack available:** FastAPI, SQLAlchemy, React 19, TanStack Query v5, shadcn/ui
**Established patterns:**
- API routes with Pydantic schemas
- TanStack Query hooks for data fetching
- Feature-based folder structure
- StatsSummary component for metric cards

**From 08-CONTEXT.md:**
- Scrape duration trends (line charts showing speed over days/weeks)
- Success/failure rates (reliability patterns by platform)
- Event counts over time (tracking capture volume)
- Clean, card-based layout consistent with existing UI
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add analytics API endpoint</name>
  <files>src/api/routes/scrape.py, src/api/schemas/scheduler.py</files>
  <action>
Add GET /api/scrape/analytics endpoint returning aggregated scrape metrics:

1. Create ScrapeAnalyticsResponse schema in scheduler.py:
   ```python
   class DailyMetric(BaseModel):
       date: str  # YYYY-MM-DD
       avg_duration_seconds: float
       total_events: int
       success_count: int
       failure_count: int
       partial_count: int

   class PlatformMetric(BaseModel):
       platform: str
       success_rate: float  # 0-100
       avg_duration_seconds: float
       total_events: int

   class ScrapeAnalyticsResponse(BaseModel):
       daily_metrics: list[DailyMetric]  # Last 14 days by default
       platform_metrics: list[PlatformMetric]  # Per-platform aggregates
       period_start: str
       period_end: str
   ```

2. Add endpoint in scrape.py:
   - Query parameter: days (int, default=14, max=30)
   - Aggregate ScrapeRun data by date:
     - Group by DATE(started_at)
     - Calculate avg duration, total events, status counts
   - Aggregate platform_timings JSON across all runs:
     - Calculate per-platform success rate (from ScrapeError counts)
     - Calculate per-platform avg duration and total events

3. Use SQLAlchemy func.date(), func.avg(), func.sum(), func.count() for aggregation
4. Filter to runs with status in (completed, partial, failed) - exclude pending/running

Return data suitable for charting without additional client-side transformation.
  </action>
  <verify>curl http://localhost:8000/api/scrape/analytics returns JSON with daily_metrics and platform_metrics arrays</verify>
  <done>Analytics endpoint returns aggregated daily metrics and per-platform success rates</done>
</task>

<task type="auto">
  <name>Task 2: Install Recharts and create chart components</name>
  <files>web/package.json, web/src/features/scrape-runs/components/analytics-charts.tsx, web/src/features/scrape-runs/components/index.ts</files>
  <action>
Install Recharts and create chart components for analytics visualization:

1. Install recharts: `cd web && pnpm add recharts`

2. Create analytics-charts.tsx with three chart components:

   a) DurationTrendChart:
      - Line chart showing avg_duration_seconds over time
      - X-axis: date, Y-axis: duration in seconds
      - Tooltip showing exact value on hover
      - Responsive container

   b) SuccessRateChart:
      - Bar chart showing success/failure/partial counts per day
      - Stacked bars with colors (green=success, yellow=partial, red=failure)
      - X-axis: date, Y-axis: count
      - Legend at bottom

   c) PlatformHealthChart:
      - Horizontal bar chart showing per-platform metrics
      - Show success_rate as percentage bar
      - Show avg_duration as label
      - Platform-specific colors (betpawa=green, sportybet=blue, bet9ja=orange)

3. Use shadcn Card wrapper for consistent styling
4. Handle loading/empty states gracefully
5. Export all charts from components/index.ts

Keep charts simple and readable - avoid data-dense Grafana style per context requirements.
  </action>
  <verify>TypeScript compiles, recharts in package.json, chart components export correctly</verify>
  <done>Recharts installed, three chart components created for duration, success rate, and platform health</done>
</task>

<task type="auto">
  <name>Task 3: Add analytics section to Scrape Runs page</name>
  <files>web/src/features/scrape-runs/hooks/use-analytics.ts, web/src/features/scrape-runs/hooks/index.ts, web/src/features/scrape-runs/index.tsx</files>
  <action>
Create analytics hook and integrate charts into Scrape Runs page:

1. Create use-analytics.ts hook:
   ```typescript
   interface AnalyticsParams {
     days?: number;  // default 14
   }

   export function useAnalytics(params?: AnalyticsParams) {
     return useQuery({
       queryKey: ['scrape-analytics', params?.days ?? 14],
       queryFn: () => api.get<ScrapeAnalyticsResponse>(`/api/scrape/analytics?days=${params?.days ?? 14}`),
       staleTime: 5 * 60 * 1000,  // 5 minutes
     });
   }
   ```

2. Export from hooks/index.ts

3. Modify index.tsx (ScrapeRunsPage):
   - Add analytics section below StatsSummary (or as separate tab if preferred)
   - Layout: 2-column grid on desktop, stacked on mobile
     - Left: DurationTrendChart
     - Right: SuccessRateChart
     - Full width below: PlatformHealthChart
   - Add period selector (7d, 14d, 30d) using shadcn Select
   - Handle loading state with skeleton placeholders
   - Handle empty state gracefully ("No data for selected period")

4. Keep the existing RunsTable below the analytics section

The page flow should be: Stats Summary cards -> Analytics charts -> Runs history table
  </action>
  <verify>Navigate to /scrape-runs, verify charts render with real data, period selector changes data range</verify>
  <done>Scrape Runs page displays analytics charts with duration trends, success rates, and platform health</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `cd web && npm run build` succeeds without errors
- [ ] GET /api/scrape/analytics returns valid aggregated data
- [ ] DurationTrendChart shows line graph of duration over time
- [ ] SuccessRateChart shows stacked bar chart of status counts
- [ ] PlatformHealthChart shows per-platform success rates
- [ ] Period selector (7d/14d/30d) updates all charts
- [ ] Charts handle empty data gracefully
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Analytics section visible on Scrape Runs page
- Charts render with real data from API
- Clean, card-based layout consistent with existing UI
- Responsive on mobile (charts stack vertically)
</success_criteria>

<output>
After completion, create `.planning/phases/08-scrape-runs-ui-improvements/08-02-SUMMARY.md`
</output>
