# Phase 7.2: Scraping Performance - Research

**Researched:** 2026-01-21
**Domain:** Python async optimization, FastAPI streaming, structured logging
**Confidence:** HIGH

<research_summary>
## Summary

Researched performance optimization and observability patterns for the existing Python/FastAPI scraping pipeline. The current ~5 minute scrape time is largely due to sequential Bet9ja tournament scraping and lack of progress visibility.

Key findings:
1. **Parallelization** - Bet9ja scraping is sequential; needs asyncio.gather like BetPawa/SportyBet
2. **Progress streaming** - Server-Sent Events (SSE) via FastAPI StreamingResponse is ideal for one-way progress updates
3. **Structured logging** - structlog with JSON output + context variables for correlation IDs
4. **Database schema** - Extend ScrapeRun with per-platform timing metrics

**Primary recommendation:** Parallelize Bet9ja scraping, add SSE endpoint for live progress, store detailed metrics per run.
</research_summary>

<standard_stack>
## Standard Stack

### Core (Already Using)
| Library | Version | Purpose | Status |
|---------|---------|---------|--------|
| asyncio | stdlib | Async concurrency | In use, needs expansion |
| FastAPI | 0.115+ | API framework | In use |
| httpx | 0.27+ | Async HTTP client | In use |
| SQLAlchemy | 2.0+ | Async ORM | In use |

### New/Enhanced
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| structlog | 24.4+ | Structured JSON logging | Replace basic logging |
| sse-starlette | 2.2+ | SSE helper for FastAPI | Optional - can use raw StreamingResponse |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| SSE | WebSocket | WebSocket is bidirectional overkill for progress reporting |
| structlog | standard logging | structlog provides better JSON + context vars |
| sse-starlette | raw StreamingResponse | sse-starlette simplifies format, but adds dependency |

**Installation (optional):**
```bash
pip install structlog sse-starlette
```
</standard_stack>

<architecture_patterns>
## Architecture Patterns

### Pattern 1: Parallel Tournament Scraping
**What:** Convert sequential Bet9ja loop to asyncio.gather with semaphore
**Current problem:** Line 616-632 in orchestrator.py iterates sequentially

**Before (current):**
```python
for tournament_id in tournament_ids:
    try:
        tournament_events = await client.fetch_events(tournament_id)
        # ...
    except Exception as e:
        logger.warning(...)
    await asyncio.sleep(0.2)  # Sequential delay
```

**After (parallel):**
```python
semaphore = asyncio.Semaphore(10)

async def fetch_tournament(tournament_id: str) -> list[dict]:
    async with semaphore:
        try:
            events = await client.fetch_events(tournament_id)
            await asyncio.sleep(0.05)  # Rate limit per request
            return events
        except Exception as e:
            logger.warning(f"Failed {tournament_id}: {e}")
            return []

results = await asyncio.gather(
    *[fetch_tournament(tid) for tid in tournament_ids],
    return_exceptions=True
)
```

### Pattern 2: SSE Progress Streaming
**What:** Stream scraping progress to frontend via Server-Sent Events
**Format:** `text/event-stream` with `data:` prefixed JSON lines

**FastAPI endpoint:**
```python
from fastapi.responses import StreamingResponse

@router.get("/scrape/stream")
async def stream_scrape_progress(request: Request):
    async def generate():
        async for progress in orchestrator.scrape_with_progress():
            if await request.is_disconnected():
                break
            yield f"data: {progress.model_dump_json()}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )
```

**React consumption:**
```typescript
const eventSource = new EventSource('/api/scrape/stream');
eventSource.onmessage = (event) => {
  const progress = JSON.parse(event.data);
  queryClient.setQueryData(['scrape-progress'], progress);
};
```

### Pattern 3: Progress Callback in Orchestrator
**What:** Yield progress updates during scraping via async generator
**Benefit:** Decouples progress reporting from transport (SSE, WebSocket, logging)

```python
async def scrape_with_progress(
    self,
    platforms: list[Platform] | None = None,
) -> AsyncGenerator[ScrapeProgress, None]:
    """Scrape all platforms, yielding progress updates."""
    target_platforms = platforms or list(Platform)
    total = len(target_platforms)

    for i, platform in enumerate(target_platforms):
        yield ScrapeProgress(
            platform=platform,
            phase="starting",
            current=i,
            total=total,
        )

        result = await self._scrape_platform(platform, ...)

        yield ScrapeProgress(
            platform=platform,
            phase="completed",
            current=i + 1,
            total=total,
            events_count=len(result),
        )
```

### Pattern 4: Structured Logging with Context
**What:** Use structlog for JSON logging with request correlation
**Benefit:** Logs are queryable, can be stored in DB per scrape run

```python
import structlog

# Configure once at startup
structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer(),
    ],
    wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),
)

# In scrape job
structlog.contextvars.bind_contextvars(scrape_run_id=run_id)
logger = structlog.get_logger()
logger.info("Starting platform scrape", platform="betpawa", tournaments=len(tournaments))
```

### Anti-Patterns to Avoid
- **Sequential HTTP requests in loop:** Always use asyncio.gather for independent requests
- **Blocking sleep():** Use asyncio.sleep() for non-blocking delays
- **Unbounded concurrency:** Always use Semaphore to limit parallel requests
- **Polling for progress:** Use SSE push instead of client polling
</architecture_patterns>

<dont_hand_roll>
## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| SSE message formatting | Manual `f"data: {x}\n\n"` | sse-starlette or consistent helper | Easy to get format wrong |
| JSON structured logging | Custom JSON formatter | structlog | Handles edge cases, context vars |
| Request correlation IDs | Manual thread-local | structlog.contextvars | Async-safe, automatic propagation |
| Client disconnection detection | Polling | `await request.is_disconnected()` | Built into Starlette |

**Key insight:** The patterns here are well-established. The main work is wiring them together properly, not inventing new approaches.
</dont_hand_roll>

<common_pitfalls>
## Common Pitfalls

### Pitfall 1: SSE Connection Leaks
**What goes wrong:** Server keeps generating events after client disconnects
**Why it happens:** Not checking `request.is_disconnected()` in generator loop
**How to avoid:** Check disconnection status on each iteration
**Warning signs:** Memory/CPU creep, orphaned async generators

### Pitfall 2: Semaphore Deadlock
**What goes wrong:** Scraping hangs indefinitely
**Why it happens:** Exception raised inside `async with semaphore` block doesn't release
**How to avoid:** Use try/finally or ensure exceptions are caught inside the context
**Warning signs:** Scrape never completes, no errors logged

### Pitfall 3: Too Aggressive Parallelization
**What goes wrong:** API rate limits triggered, requests fail
**Why it happens:** Semaphore limit too high (e.g., 50 concurrent)
**How to avoid:** Start conservative (5-10), increase based on API behavior
**Warning signs:** 429 errors, connection refused, partial failures

### Pitfall 4: SSE Not Reaching Frontend
**What goes wrong:** Events stream in backend but frontend doesn't receive
**Why it happens:** Proxy/nginx buffers SSE responses, CORS issues
**How to avoid:** Set `X-Accel-Buffering: no` header, configure proxy
**Warning signs:** Works locally, fails in production

### Pitfall 5: Large Log Storage
**What goes wrong:** Database grows rapidly with stored logs
**Why it happens:** Storing every debug log for every scrape run
**How to avoid:** Only store summary metrics + errors, not full debug logs
**Warning signs:** Database size growth, slow queries on scrape_runs
</common_pitfalls>

<code_examples>
## Code Examples

### SSE Progress Endpoint (FastAPI)
```python
# Source: FastAPI docs + sse-starlette patterns
from fastapi import Request
from fastapi.responses import StreamingResponse

@router.get("/scrape/stream")
async def stream_scrape(
    request: Request,
    db: AsyncSession = Depends(get_db),
):
    """Stream scrape progress via Server-Sent Events."""

    async def event_generator():
        orchestrator = get_orchestrator(request)

        async for progress in orchestrator.scrape_with_progress(db=db):
            # Check if client disconnected
            if await request.is_disconnected():
                break

            # Format as SSE
            data = progress.model_dump_json()
            yield f"data: {data}\n\n"

        # Final event
        yield f"data: {json.dumps({'status': 'complete'})}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # Disable nginx buffering
        },
    )
```

### React EventSource Hook
```typescript
// Source: TanStack Query + EventSource pattern
function useScrapeProgress() {
  const queryClient = useQueryClient();
  const [isStreaming, setIsStreaming] = useState(false);

  const startScrape = useCallback(() => {
    setIsStreaming(true);
    const eventSource = new EventSource('/api/scrape/stream');

    eventSource.onmessage = (event) => {
      const progress = JSON.parse(event.data);
      queryClient.setQueryData(['scrape-progress'], progress);

      if (progress.status === 'complete') {
        eventSource.close();
        setIsStreaming(false);
        // Invalidate events query to refresh list
        queryClient.invalidateQueries({ queryKey: ['events'] });
      }
    };

    eventSource.onerror = () => {
      eventSource.close();
      setIsStreaming(false);
    };

    return () => eventSource.close();
  }, [queryClient]);

  return { startScrape, isStreaming };
}
```

### Parallel Tournament Scraping
```python
# Source: Current codebase pattern extended
async def _scrape_bet9ja_parallel(
    self,
    client: Bet9jaClient,
    tournament_ids: list[str],
    on_progress: Callable[[str, int], None] | None = None,
) -> list[dict]:
    """Scrape Bet9ja tournaments in parallel."""
    semaphore = asyncio.Semaphore(10)
    events: list[dict] = []
    completed = 0

    async def fetch_tournament(tid: str) -> list[dict]:
        nonlocal completed
        async with semaphore:
            try:
                result = await client.fetch_events(tid)
                completed += 1
                if on_progress:
                    on_progress(tid, completed)
                await asyncio.sleep(0.05)  # Rate limit
                return result
            except Exception as e:
                logger.warning(f"Failed tournament {tid}: {e}")
                completed += 1
                return []

    results = await asyncio.gather(
        *[fetch_tournament(tid) for tid in tournament_ids],
        return_exceptions=True,
    )

    for result in results:
        if isinstance(result, list):
            events.extend(result)

    return events
```
</code_examples>

<sota_updates>
## State of the Art (2025-2026)

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Polling for progress | SSE for push updates | Established | Simpler, more efficient |
| print() debugging | structlog JSON | 2023+ | Production-ready logs |
| Sequential API calls | asyncio.gather + Semaphore | Standard | 5-10x speedup |

**New patterns to consider:**
- **structlog contextvars:** Automatic correlation ID propagation in async code
- **TanStack Query setQueryData:** SSE updates directly into cache

**No deprecated patterns in current stack.**
</sota_updates>

<open_questions>
## Open Questions

1. **Scrape run log storage depth**
   - What we know: Can store summary metrics + errors
   - What's unclear: How much detail to store per run for UI drill-down
   - Recommendation: Start with per-platform timing + event counts + errors, add more if needed

2. **Progress update frequency**
   - What we know: Can yield progress on each event or each platform
   - What's unclear: What granularity the UI needs (per-event vs per-platform)
   - Recommendation: Per-platform is sufficient for <2min scrape, avoid per-event overhead
</open_questions>

<sources>
## Sources

### Primary (HIGH confidence)
- FastAPI official docs - Custom Response, StreamingResponse
- Current codebase - orchestrator.py patterns already working

### Secondary (MEDIUM confidence)
- [FastAPI SSE patterns](https://mahdijafaridev.medium.com/implementing-server-sent-events-sse-with-fastapi-real-time-updates-made-simple-6492f8bfc154) - Verified with FastAPI docs
- [TanStack Query + SSE](https://github.com/TanStack/query/discussions/418) - Standard pattern using setQueryData
- [structlog FastAPI integration](https://wazaari.dev/blog/fastapi-structlog-integration) - JSON logging + context vars

### Tertiary (LOW confidence - needs validation)
- sse-starlette package - Optional convenience, raw StreamingResponse works fine
</sources>

<metadata>
## Metadata

**Research scope:**
- Core technology: Python asyncio, FastAPI
- Ecosystem: structlog, SSE
- Patterns: Parallel scraping, progress streaming, structured logging
- Pitfalls: Rate limiting, connection handling, log storage

**Confidence breakdown:**
- Standard stack: HIGH - all libraries already in use or well-established
- Architecture: HIGH - patterns proven in current codebase
- Pitfalls: HIGH - documented issues, straightforward mitigations
- Code examples: HIGH - based on current codebase patterns

**Research date:** 2026-01-21
**Valid until:** 2026-02-21 (30 days - stable technologies)
</metadata>

---

*Phase: 07.2-scraping-performance*
*Research completed: 2026-01-21*
*Ready for planning: yes*
