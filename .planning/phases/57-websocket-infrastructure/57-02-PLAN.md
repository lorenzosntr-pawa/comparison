---
phase: 57-websocket-infrastructure
plan: 02
type: execute
---

<objective>
Define WebSocket message protocol and integrate scrape progress broadcasting via WebSocket.

Purpose: Enable real-time scrape progress delivery over WebSocket in parallel with existing SSE. This allows Phase 58 to migrate the frontend from EventSource to WebSocket without backend changes.
Output: Typed message schemas and automatic scrape progress forwarding to WebSocket clients subscribed to "scrape_progress" topic.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/57-websocket-infrastructure/57-01-SUMMARY.md

# Key source files:
@src/api/websocket/manager.py
@src/scraping/broadcaster.py
@src/scraping/schemas.py
@src/api/routes/scrape.py

**Tech stack available:** FastAPI WebSocket, asyncio, structlog, Pydantic v2
**Established patterns:** ProgressBroadcaster pub/sub with asyncio.Queue, ScrapeProgress Pydantic model, app.state for shared services
**Constraining decisions:**
- SSE must continue working alongside WebSocket (no breaking changes)
- ProgressBroadcaster is the central hub for scrape progress events
- ScrapeProgress schema (src/scraping/schemas.py) defines the progress data shape
</context>

<tasks>

<task type="auto">
  <name>Task 1: Define WebSocket message protocol</name>
  <files>src/api/websocket/messages.py, src/api/websocket/__init__.py</files>
  <action>
Create `src/api/websocket/messages.py` with helper functions that produce typed message dicts for WebSocket transmission.

All WebSocket messages follow this shape:
```python
{
    "type": str,       # message type discriminator
    "timestamp": str,  # ISO 8601 UTC
    "data": dict,      # payload specific to message type
}
```

Define helper functions (NOT Pydantic models — keep it lightweight, these are just dict builders):

1. `scrape_progress_message(progress: ScrapeProgress) -> dict`
   - type: "scrape_progress"
   - data: progress.model_dump(mode="json") — leverages existing Pydantic serialization
   - This gives the exact same data shape the SSE endpoint sends

2. `odds_update_message(event_ids: list[int], source: str, snapshot_count: int) -> dict`
   - type: "odds_update"
   - data: {"event_ids": [...], "source": source, "snapshot_count": snapshot_count}
   - Lightweight notification — frontend fetches full data from cache-first API
   - source is "betpawa", "sportybet", or "bet9ja"

3. `connection_ack_message(topics: list[str]) -> dict`
   - type: "connection_ack"
   - data: {"topics": topics}

4. `pong_message() -> dict`
   - type: "pong"
   - data: {} (empty)

5. `error_message(code: str, detail: str) -> dict`
   - type: "error"
   - data: {"code": code, "detail": detail}

All functions add `"timestamp": datetime.utcnow().isoformat() + "Z"` automatically.

Update `src/api/websocket/__init__.py` to export message functions alongside ConnectionManager.

Update `src/api/routes/ws.py` to use `connection_ack_message()` and `pong_message()` from the messages module (replace inline dict construction from 57-01).
  </action>
  <verify>
```bash
python -c "
from src.scraping.schemas import ScrapeProgress, ScrapePhase
from src.api.websocket.messages import scrape_progress_message, odds_update_message, connection_ack_message, pong_message, error_message

# Test scrape progress message
p = ScrapeProgress(phase=ScrapePhase.SCRAPING, current=1, total=3, events_count=50)
msg = scrape_progress_message(p)
assert msg['type'] == 'scrape_progress'
assert msg['data']['phase'] == 'scraping'
assert 'timestamp' in msg

# Test odds update message
msg = odds_update_message([1, 2, 3], 'betpawa', 3)
assert msg['type'] == 'odds_update'
assert msg['data']['event_ids'] == [1, 2, 3]

# Test connection ack
msg = connection_ack_message(['scrape_progress', 'odds_updates'])
assert msg['type'] == 'connection_ack'

print('ALL MESSAGE TESTS PASSED')
"
```
  </verify>
  <done>Five message builder functions producing correctly shaped dicts, connection_ack_message and pong_message used in ws.py endpoint, all messages include type discriminator and timestamp</done>
</task>

<task type="auto">
  <name>Task 2: Bridge ProgressBroadcaster to WebSocket clients</name>
  <files>src/api/websocket/bridge.py, src/api/routes/scrape.py, src/api/websocket/__init__.py</files>
  <action>
Create `src/api/websocket/bridge.py` with a bridge function that subscribes to a ProgressBroadcaster and forwards events to WebSocket clients.

**Bridge design:**

```python
async def bridge_scrape_to_websocket(
    broadcaster: ProgressBroadcaster,
    ws_manager: ConnectionManager,
) -> None:
```

This function:
1. Subscribes to the broadcaster via `broadcaster.subscribe()`
2. Iterates the async generator
3. For each ScrapeProgress event, converts to WebSocket message via `scrape_progress_message(progress)` and broadcasts via `ws_manager.broadcast(message, topic="scrape_progress")`
4. Runs until the broadcaster signals completion (generator ends)
5. Logs start/end with structlog: `ws.bridge.started` (scrape_run_id), `ws.bridge.ended` (scrape_run_id, events_forwarded)
6. Catches exceptions to ensure the bridge doesn't crash the scrape — log error and exit gracefully

**Integration in `src/api/routes/scrape.py`:**

In the `run_scrape_background()` function (around line 182), after the broadcaster is created and before the scrape starts:

1. Get the ConnectionManager: `ws_manager = getattr(request.app.state, "ws_manager", None)`
2. If `ws_manager` is not None AND `ws_manager.active_count > 0` (avoid creating bridge task when nobody is listening):
   - Create a background task: `bridge_task = asyncio.create_task(bridge_scrape_to_websocket(broadcaster, ws_manager))`
3. After the scrape completes (in the finally block or after broadcaster.close()), cancel the bridge task if it's still running: `bridge_task.cancel()` with `suppress(asyncio.CancelledError)`

Important: The bridge task runs IN PARALLEL with the existing SSE streaming. It subscribes as just another subscriber to the same broadcaster. SSE subscribers continue to work exactly as before.

The bridge should also handle the case where `ws_manager.topic_counts.get("scrape_progress", 0) == 0` — skip broadcasting (nobody subscribed to this topic). Check this INSIDE the loop, not just at startup, since clients may connect/disconnect during the scrape.

Actually, this check is unnecessary complexity — `ws_manager.broadcast()` already handles empty subscriber sets gracefully (iterates empty set, does nothing). Remove the topic count check. Let broadcast handle it.

Also modify the `/api/scrape/runs/{scrape_run_id}/progress` endpoint (the "observe" endpoint) similarly — if a client connects to observe an existing scrape's progress, the bridge is already running (it was started when the scrape started). No additional work needed for the observe endpoint.

Update `src/api/websocket/__init__.py` to export `bridge_scrape_to_websocket`.

Do NOT modify the ProgressBroadcaster class itself — the bridge is a consumer, not a modification of the publisher.
  </action>
  <verify>
Start the dev server. Open two terminals:

Terminal 1 — WebSocket client subscribing to scrape_progress:
```bash
python -c "
import asyncio, websockets, json
async def listen():
    async with websockets.connect('ws://localhost:8000/api/ws?topics=scrape_progress') as ws:
        ack = json.loads(await ws.recv())
        print('Connected:', ack)
        print('Waiting for scrape progress...')
        while True:
            msg = json.loads(await ws.recv())
            print(f'  [{msg[\"type\"]}] {msg[\"data\"].get(\"phase\", \"?\")} - {msg[\"data\"].get(\"message\", \"\")}')
            if msg['data'].get('phase') in ('completed', 'failed'):
                break
        print('SCRAPE COMPLETE VIA WEBSOCKET')
asyncio.run(listen())
"
```

Terminal 2 — Trigger a scrape:
```bash
curl http://localhost:8000/api/scrape/stream -N
```

Verify: WebSocket client receives scrape_progress messages in real time, SSE stream also works simultaneously.
  </verify>
  <done>Bridge function forwards ProgressBroadcaster events to WebSocket clients, bridge task created automatically when scrape starts, SSE continues working alongside WebSocket, no modifications to ProgressBroadcaster class</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] All 5 message builder functions work correctly
- [ ] WebSocket endpoint uses message functions (not inline dicts)
- [ ] Bridge task starts when scrape begins and WebSocket clients exist
- [ ] Scrape progress events received via WebSocket in real time
- [ ] SSE endpoints still work (no regression)
- [ ] Bridge handles scrape completion/failure gracefully
- [ ] No import errors, server starts cleanly
</verification>

<success_criteria>

- WebSocket message protocol with 5 message types
- Automatic bridge from ProgressBroadcaster to WebSocket
- Scrape progress delivered via both SSE and WebSocket simultaneously
- No changes to ProgressBroadcaster class
- No regression on existing SSE functionality
</success_criteria>

<output>
After completion, create `.planning/phases/57-websocket-infrastructure/57-02-SUMMARY.md`
</output>
