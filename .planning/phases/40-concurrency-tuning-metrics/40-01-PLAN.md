---
phase: 40-concurrency-tuning-metrics
plan: 01
type: execute
domain: backend
---

<objective>
Make semaphore limits and delays configurable via Settings, and add metrics API for new event-centric scraping flow.

Purpose: Enable runtime tuning of scraping concurrency without code changes, and provide observability for the new EventCoordinator flow via EventScrapeStatus data.
Output: Configurable scraping tuning settings, EventCoordinator using settings, and new metrics API endpoint.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase summaries (dependency chain):
@.planning/phases/36-investigation-architecture-design/36-01-SUMMARY.md
@.planning/phases/37-event-coordination-layer/37-01-SUMMARY.md
@.planning/phases/38-sr-id-parallel-scraping/38-01-SUMMARY.md
@.planning/phases/39-batch-db-storage/39-01-SUMMARY.md

# Key source files:
@src/db/models/settings.py
@src/api/schemas/settings.py
@src/api/routes/settings.py
@src/scraping/event_coordinator.py
@src/db/models/event_scrape_status.py

**Tech stack available:**
- SQLAlchemy 2.0 async with Mapped[] columns
- Pydantic v2 with ConfigDict
- FastAPI with dependency injection
- Existing Settings singleton pattern (id=1)

**Constraining decisions from prior phases:**
- Phase 36: Semaphore limits: BetPawa 50, SportyBet 50, Bet9ja 15+25ms delay
- Phase 36: Batch size of 50 events for optimal throughput
- Phase 38: PLATFORM_SEMAPHORES and BET9JA_DELAY_MS are currently hardcoded constants
- Phase 39: EventScrapeStatus tracks per-event timing, platforms_scraped/failed

**Current state:**
- PLATFORM_SEMAPHORES = {"betpawa": 50, "sportybet": 50, "bet9ja": 15}
- BET9JA_DELAY_MS = 25
- batch_size = 50 (constructor default)
- All values hardcoded in event_coordinator.py lines 49-54 and 79
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Scraping Tuning Settings to DB and API</name>
  <files>
    src/db/models/settings.py,
    src/api/schemas/settings.py,
    alembic/versions/[new]_add_scraping_tuning_settings.py
  </files>
  <action>
1. Update Settings model in src/db/models/settings.py to add:
   - betpawa_concurrency: Mapped[int] = mapped_column(default=50)
   - sportybet_concurrency: Mapped[int] = mapped_column(default=50)
   - bet9ja_concurrency: Mapped[int] = mapped_column(default=15)
   - bet9ja_delay_ms: Mapped[int] = mapped_column(default=25)
   - batch_size: Mapped[int] = mapped_column(default=50)

2. Update SettingsResponse in src/api/schemas/settings.py to include the new fields.

3. Update SettingsUpdate in src/api/schemas/settings.py with optional fields:
   - betpawa_concurrency: int | None = Field(default=None, ge=1, le=100)
   - sportybet_concurrency: int | None = Field(default=None, ge=1, le=100)
   - bet9ja_concurrency: int | None = Field(default=None, ge=1, le=50)
   - bet9ja_delay_ms: int | None = Field(default=None, ge=0, le=100)
   - batch_size: int | None = Field(default=None, ge=10, le=200)

4. Create Alembic migration to add columns with defaults. Use op.add_column with server_default then remove default after.

Note: The settings API routes already handle dynamic field updates, so no route changes needed.
  </action>
  <verify>
1. Run: alembic upgrade head (migration succeeds)
2. Run: python -c "from src.db.models.settings import Settings; print(Settings.__table__.columns.keys())" (shows new columns)
3. Manually verify API: curl http://localhost:8000/api/settings returns new fields with default values
  </verify>
  <done>
- Settings model has 5 new columns for scraping tuning
- SettingsResponse and SettingsUpdate schemas include new fields
- Migration applied, existing settings row has default values
- GET/PUT /api/settings works with new fields
  </done>
</task>

<task type="auto">
  <name>Task 2: Use Configurable Settings in EventCoordinator</name>
  <files>src/scraping/event_coordinator.py</files>
  <action>
1. Modify EventCoordinator to accept tuning settings in __init__:
   ```python
   def __init__(
       self,
       betpawa_client: BetPawaClient,
       sportybet_client: SportyBetClient,
       bet9ja_client: Bet9jaClient,
       batch_size: int = 50,
       platform_concurrency: dict[str, int] | None = None,
       bet9ja_delay_ms: int = 25,
   ) -> None:
   ```

2. Store settings as instance attributes:
   ```python
   self._batch_size = batch_size
   self._platform_concurrency = platform_concurrency or {
       "betpawa": 50,
       "sportybet": 50,
       "bet9ja": 15,
   }
   self._bet9ja_delay_ms = bet9ja_delay_ms
   ```

3. Update scrape_batch() to use self._platform_concurrency instead of PLATFORM_SEMAPHORES:
   - Line 750: `for platform, limit in self._platform_concurrency.items()`

4. Update _scrape_event_all_platforms() to use self._bet9ja_delay_ms instead of BET9JA_DELAY_MS:
   - Line 693: `await asyncio.sleep(self._bet9ja_delay_ms / 1000)`

5. Keep the module-level constants (PLATFORM_SEMAPHORES, BET9JA_DELAY_MS) as documentation of defaults but mark them with a comment: "# Default values - use instance attributes for actual limits"

6. Add a class method to create EventCoordinator from Settings object:
   ```python
   @classmethod
   def from_settings(
       cls,
       betpawa_client: BetPawaClient,
       sportybet_client: SportyBetClient,
       bet9ja_client: Bet9jaClient,
       settings: Settings,
   ) -> "EventCoordinator":
       """Create EventCoordinator with tuning from Settings model."""
       return cls(
           betpawa_client=betpawa_client,
           sportybet_client=sportybet_client,
           bet9ja_client=bet9ja_client,
           batch_size=settings.batch_size,
           platform_concurrency={
               "betpawa": settings.betpawa_concurrency,
               "sportybet": settings.sportybet_concurrency,
               "bet9ja": settings.bet9ja_concurrency,
           },
           bet9ja_delay_ms=settings.bet9ja_delay_ms,
       )
   ```

Note: Add TYPE_CHECKING import for Settings to avoid circular imports.
  </action>
  <verify>
1. Run: python -c "from src.scraping.event_coordinator import EventCoordinator; print('imports ok')"
2. Run: python -c "
from src.scraping.event_coordinator import EventCoordinator
from unittest.mock import MagicMock
coord = EventCoordinator(MagicMock(), MagicMock(), MagicMock(), batch_size=25, platform_concurrency={'betpawa': 10, 'sportybet': 10, 'bet9ja': 5}, bet9ja_delay_ms=50)
print(f'batch_size={coord._batch_size}, bp_conc={coord._platform_concurrency[\"betpawa\"]}, bet9ja_delay={coord._bet9ja_delay_ms}')
"
# Should print: batch_size=25, bp_conc=10, bet9ja_delay=50
  </verify>
  <done>
- EventCoordinator accepts tuning parameters in __init__
- Instance attributes used instead of module constants
- from_settings() class method available for Settings integration
- Default values match Phase 36 recommendations (50/50/15, 25ms, batch 50)
  </done>
</task>

<task type="auto">
  <name>Task 3: Add Event Scrape Metrics API Endpoint</name>
  <files>
    src/api/routes/scrape.py,
    src/api/schemas/scrape.py
  </files>
  <action>
1. Add new Pydantic schemas in src/api/schemas/scrape.py (or create src/api/schemas/event_metrics.py if cleaner):
   ```python
   class EventMetricsByPlatform(BaseModel):
       """Per-platform metrics from EventScrapeStatus."""
       model_config = ConfigDict(alias_generator=to_camel, populate_by_name=True)

       platform: str
       total_requested: int
       total_scraped: int
       total_failed: int
       success_rate: float  # percentage
       avg_timing_ms: float

   class EventScrapeMetricsResponse(BaseModel):
       """Response for event-level scrape metrics."""
       model_config = ConfigDict(alias_generator=to_camel, populate_by_name=True)

       period_start: str
       period_end: str
       total_events: int
       events_fully_scraped: int  # all requested platforms succeeded
       events_partially_scraped: int  # some platforms succeeded
       events_failed: int  # no platforms succeeded
       platform_metrics: list[EventMetricsByPlatform]
   ```

2. Add new endpoint in src/api/routes/scrape.py:
   ```python
   @router.get("/event-metrics", response_model=EventScrapeMetricsResponse)
   async def get_event_scrape_metrics(
       db: AsyncSession = Depends(get_db),
       days: int = Query(default=7, ge=1, le=30, description="Number of days to analyze"),
   ) -> EventScrapeMetricsResponse:
       """Get metrics from EventScrapeStatus for the new event-centric scraping flow.

       Aggregates per-event scrape results to show platform success rates
       and timing from the EventCoordinator flow.
       """
   ```

3. Implementation:
   - Query EventScrapeStatus for records in the date range
   - Aggregate: total events, fully/partially/failed counts
   - For each platform, count appearances in platforms_requested/scraped/failed arrays
   - Calculate avg timing_ms per platform
   - Return structured response

4. Register the schema exports in src/api/schemas/__init__.py if creating new file.
  </action>
  <verify>
1. Run: python -c "from src.api.schemas.scrape import EventScrapeMetricsResponse; print('schema ok')"
2. Start server and test endpoint:
   curl http://localhost:8000/api/scrape/event-metrics
   # Should return JSON with period_start, period_end, total_events, platform_metrics
3. If no EventScrapeStatus data exists yet, should return zeros gracefully
  </verify>
  <done>
- EventScrapeMetricsResponse schema defined with platform breakdown
- GET /api/scrape/event-metrics endpoint returns aggregated metrics
- Metrics include success rates and timing per platform
- Handles empty data gracefully (zeros, no errors)
  </done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `alembic upgrade head` succeeds
- [ ] GET /api/settings returns new tuning fields
- [ ] PUT /api/settings can update tuning values
- [ ] EventCoordinator accepts custom tuning parameters
- [ ] EventCoordinator.from_settings() creates instance from Settings
- [ ] GET /api/scrape/event-metrics returns valid response
- [ ] No type errors: `python -m py_compile src/scraping/event_coordinator.py src/api/routes/scrape.py`
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No errors or warnings introduced
- Scraping tuning is configurable via Settings API
- EventCoordinator uses configurable values
- Event-level metrics available via new API endpoint
</success_criteria>

<output>
After completion, create `.planning/phases/40-concurrency-tuning-metrics/40-01-SUMMARY.md`:

# Phase 40 Plan 01: Concurrency Tuning & Metrics Summary

**[One-liner summary]**

## Accomplishments

- Added scraping tuning settings to Settings model
- EventCoordinator uses configurable concurrency limits
- New /api/scrape/event-metrics endpoint for new flow analytics

## Files Created/Modified

- `src/db/models/settings.py` - Added tuning columns
- `src/api/schemas/settings.py` - Added tuning fields to schemas
- `alembic/versions/xxx_add_scraping_tuning_settings.py` - Migration
- `src/scraping/event_coordinator.py` - Configurable tuning
- `src/api/routes/scrape.py` - Event metrics endpoint
- `src/api/schemas/scrape.py` - EventScrapeMetricsResponse

## Decisions Made

[Document any decisions]

## Issues Encountered

[Document any issues]

## Next Phase Readiness

Ready for Phase 41: On-Demand API (POST /api/scrape/{sr_id})
</output>
