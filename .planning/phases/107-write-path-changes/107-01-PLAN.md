---
phase: 107-write-path-changes
plan: 01
type: execute
---

<objective>
Create market-level data structures and change detection for new storage architecture.

Purpose: Enable per-market change tracking instead of per-snapshot, which currently writes ALL 50+ markets when ANY single market changes. Market-level detection is prerequisite for 95% storage reduction.

Output: New DTOs in write_queue.py and classify_market_changes() function in change_detection.py that returns which individual markets changed vs unchanged.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase context:
@.planning/phases/105-investigation-schema-design/105-01-SUMMARY.md
@.planning/phases/106-schema-migration/106-01-SUMMARY.md

# Key source files:
@src/storage/write_queue.py
@src/caching/change_detection.py
@src/caching/odds_cache.py
@src/db/models/market_odds.py

**Tech stack available:** PostgreSQL, SQLAlchemy 2.0, Pydantic v2, frozen dataclasses
**Established patterns:** Frozen dataclass DTOs, normalized outcome comparison

**Constraining decisions:**
- Phase 105: Market-level change detection instead of snapshot-level
- Phase 105: Unified storage for BetPawa + competitors using bookmaker_slug
- Phase 106: market_odds_current (UPSERT) + market_odds_history (append-only) tables created
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create market-level DTOs in write_queue.py</name>
  <files>src/storage/write_queue.py</files>
  <action>
Add new frozen dataclasses for market-level writes:

1. `MarketCurrentWrite` - represents a single market write to market_odds_current:
   ```python
   @dataclass(frozen=True)
   class MarketCurrentWrite:
       event_id: int
       bookmaker_slug: str  # 'betpawa', 'sportybet', 'bet9ja'
       betpawa_market_id: str
       betpawa_market_name: str
       line: float | None
       handicap_type: str | None
       handicap_home: float | None
       handicap_away: float | None
       outcomes: dict  # [{name, odds, is_active}, ...]
       market_groups: list[str] | None
       unavailable_at: datetime | None
       changed: bool  # True = also INSERT to history
   ```

2. `MarketWriteBatch` - batch of market writes:
   ```python
   @dataclass(frozen=True)
   class MarketWriteBatch:
       markets: tuple[MarketCurrentWrite, ...]
       scrape_run_id: int | None
       batch_index: int
   ```

Keep existing DTOs (MarketWriteData, SnapshotWriteData, WriteBatch, etc.) for backward compatibility during migration - the old write path still needs them until Phase 108 completes.

Export new classes in __all__ if present.
  </action>
  <verify>python -c "from src.storage.write_queue import MarketCurrentWrite, MarketWriteBatch; print('OK')"</verify>
  <done>MarketCurrentWrite and MarketWriteBatch dataclasses exist and can be imported</done>
</task>

<task type="auto">
  <name>Task 2: Implement classify_market_changes() in change_detection.py</name>
  <files>src/caching/change_detection.py, src/caching/__init__.py</files>
  <action>
Create new function that does market-level change detection:

```python
def classify_market_changes(
    cache: OddsCache,
    markets: list[tuple[int, str, list[Any]]],  # (event_id, bookmaker_slug, markets_data)
) -> list[MarketCurrentWrite]:
    """
    Compare each market against cached version and return MarketCurrentWrite list.

    Unlike classify_batch_changes which returns entire snapshots as changed/unchanged,
    this returns per-market change status via the `changed` boolean.

    For each market in input:
    - If no cached version exists: changed=True (new market)
    - If cached outcomes differ: changed=True (odds changed)
    - If cached outcomes identical: changed=False (just confirm)

    All markets get written to market_odds_current (UPSERT), but only
    changed=True markets get written to market_odds_history (INSERT).
    """
```

Implementation notes:
- Reuse existing `_normalise_outcomes()` for outcome comparison
- Use cache.get_betpawa_snapshot() or cache.get_competitor_snapshot() based on bookmaker_slug
- For BetPawa (bookmaker_slug='betpawa'), get by bookmaker_id=1 from cache
- For competitors (bookmaker_slug='sportybet'/'bet9ja'), get by source string
- Handle None cache (first scrape) as changed=True for all markets
- Build MarketCurrentWrite with all fields from input market data

Add export to src/caching/__init__.py alongside existing exports.
  </action>
  <verify>
python -c "
from src.caching import classify_market_changes
from src.caching.odds_cache import OddsCache
cache = OddsCache()
result = classify_market_changes(cache, [])
print(f'Empty input returns: {result}')
assert result == [], 'Empty input should return empty list'
print('OK')
"
  </verify>
  <done>classify_market_changes() exists, returns list of MarketCurrentWrite, handles empty input correctly</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from src.storage.write_queue import MarketCurrentWrite, MarketWriteBatch"` succeeds
- [ ] `python -c "from src.caching import classify_market_changes"` succeeds
- [ ] No Python syntax errors in modified files
- [ ] Existing write path still works (old DTOs preserved)
</verification>

<success_criteria>

- MarketCurrentWrite and MarketWriteBatch frozen dataclasses created
- classify_market_changes() implemented with per-market change detection
- Function returns MarketCurrentWrite with changed=True/False per market
- Existing classify_batch_changes() still works (backward compat)
- All imports resolve correctly
</success_criteria>

<output>
After completion, create `.planning/phases/107-write-path-changes/107-01-SUMMARY.md`
</output>
