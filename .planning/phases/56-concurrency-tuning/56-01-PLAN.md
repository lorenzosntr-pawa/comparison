---
phase: 56-concurrency-tuning
plan: 01
type: execute
---

<objective>
Enable intra-batch event concurrency so multiple events scrape simultaneously within each batch, activating the existing per-platform semaphores that are currently unused due to sequential event processing.

Purpose: Scraping is the dominant bottleneck at 61.3% of pipeline time (907s for ~1300 events). Events within each batch are processed sequentially — each event takes ~700ms (max of 3 platform calls in parallel). With 50 events/batch processed one-at-a-time, batch scrape time is ~35s. Adding concurrent event processing (e.g. 10 events in parallel) should reduce batch scrape time by ~10x, cutting total pipeline time from ~24 minutes to ~5-7 minutes.

Output: EventCoordinator with configurable intra-batch event concurrency, tuned HTTP connection pool, settings API support for concurrency parameters, and benchmark verification.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase summaries (dependency graph):
@.planning/phases/53-investigation-benchmarking/53-01-SUMMARY.md
@.planning/phases/55-async-write-pipeline/55-03-SUMMARY.md
@.planning/phases/55.1-fix-phase-55-bugs/55.1-01-SUMMARY.md

# Key source files:
@src/scraping/event_coordinator.py
@src/db/models/settings.py
@src/api/app.py
@src/api/routes/settings.py
@src/api/schemas/settings.py
@scripts/benchmark_pipeline.py

# Baseline benchmark reference:
@.planning/phases/53-investigation-benchmarking/BENCHMARK-BASELINE.md

**Tech stack available:** asyncio.Semaphore, asyncio.gather, httpx connection pools, perf_counter instrumentation
**Established patterns:** perf_counter timing on progress events, EventCoordinator.from_settings() factory, configurable Settings model

**Constraining decisions:**
- [Phase 53]: Scraping is dominant bottleneck at 61.3% — this phase addresses it
- [Phase 55]: Async write queue decouples scraping from storage — increased parallelism won't bottleneck on DB
- [Phase 55]: Cache-before-persist means API serves fresh data from cache regardless of write latency
- [Phase 55.1]: On-demand scrapes pass odds_cache and write_queue — must preserve backward compatibility

**Current concurrency state:**
- Events processed SEQUENTIALLY within each batch (`for event in batch["events"]:`)
- Platforms scraped in PARALLEL per event via `asyncio.gather()` (3 concurrent requests max)
- Per-platform semaphores exist (BP=50, SB=50, B9J=15) but are effectively unused since events are sequential
- HTTP connection pool: 100 max connections, 50 keepalive — may bottleneck under higher concurrency
- Bet9ja has a 25ms delay per request to avoid rate limiting
- Settings model has concurrency fields but update API doesn't expose them

**Key insight:** The platform semaphores were designed to control load when multiple events scrape simultaneously. Making events parallel activates these semaphores as originally intended.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add intra-batch event concurrency to EventCoordinator</name>
  <files>src/scraping/event_coordinator.py, src/db/models/settings.py</files>
  <action>
1. **Add `max_concurrent_events` field to Settings model** (src/db/models/settings.py):
   - Add `max_concurrent_events: Mapped[int] = mapped_column(default=10)` to Settings
   - Default 10: with 3 platforms each, that's up to 30 concurrent HTTP requests, well within pool limit of 100

2. **Create Alembic migration** for the new column:
   - `alembic revision --autogenerate -m "add max_concurrent_events setting"`
   - Verify and run: `alembic upgrade head`

3. **Add `max_concurrent_events` parameter to EventCoordinator**:
   - Add `max_concurrent_events: int = 10` to `__init__()` params
   - Store as `self._max_concurrent_events`
   - Add to `from_settings()`: read `settings.max_concurrent_events`

4. **Refactor `scrape_batch()` for concurrent event processing**:
   - Replace sequential `for event in batch["events"]` with concurrent processing
   - Create an `asyncio.Semaphore(self._max_concurrent_events)` to limit concurrency
   - Use `asyncio.gather()` to scrape multiple events in parallel
   - Important: `scrape_batch()` is an AsyncGenerator that yields progress events. Since parallel events complete in non-deterministic order, collect all results then yield progress in batch order (or yield as they complete — order doesn't matter for SSE)
   - Approach: Create an async task per event that acquires the event semaphore, scrapes, and appends results to a shared list. Use `asyncio.gather()` for all events in the batch. After gather completes, yield all progress events.
   - Alternative simpler approach: Use `asyncio.Semaphore` + `asyncio.create_task` to fire off all events with concurrency limit, collect results via a list, then yield progress. This avoids the AsyncGenerator complication.
   - **Chosen approach**: Refactor `scrape_batch()` to NOT be an AsyncGenerator. Instead, return a list of progress events. The caller (`run_full_cycle`) already iterates over them and can yield from the list. This is cleaner than trying to yield from parallel async generators.
   - Steps:
     a. Change `scrape_batch()` return type from `AsyncGenerator[dict, None]` to `list[dict]`
     b. Create inner async function `_scrape_single_event(event, semaphores, event_semaphore)` that acquires event_semaphore, calls `_scrape_event_all_platforms()`, updates event status/results, and returns progress dicts
     c. Use `asyncio.gather(*[_scrape_single_event(e, ...) for e in batch["events"]])`
     d. Flatten results into list of progress dicts
     e. Update `run_full_cycle()` to iterate over returned list instead of `async for`

5. **Update `run_full_cycle()` caller**:
   - Change `async for progress in self.scrape_batch(batch):` to iterate over the returned list:
     ```python
     progress_events = await self.scrape_batch(batch)
     for progress in progress_events:
         yield progress
     ```

6. **Preserve per-platform semaphores** — they already exist in `scrape_batch()` and are passed to `_scrape_event_all_platforms()`. With concurrent events, these semaphores now actually throttle per-platform load (e.g., max 15 concurrent Bet9ja requests across all parallel events).

**What to avoid:**
- Do NOT remove the per-platform semaphores — they're essential for preventing rate limiting when events run in parallel
- Do NOT change the event status/results update logic — just wrap it in the concurrent task
- Do NOT break the progress event structure — SSE streaming depends on it
- Do NOT use `asyncio.TaskGroup` — it cancels all tasks on first exception, which is too aggressive. Use `asyncio.gather(return_exceptions=True)` for partial failure tolerance
  </action>
  <verify>
- Application starts without errors
- `alembic upgrade head` succeeds
- Run a scrape via the UI button and observe logs:
  - Multiple `write_batch_processed` entries should arrive faster (batches complete quicker)
  - No rate limiting errors from platforms
  - All events still scraped successfully
  </verify>
  <done>
- `max_concurrent_events` field exists in Settings model with default=10
- Migration created and applied
- EventCoordinator accepts and uses `max_concurrent_events` parameter
- `scrape_batch()` processes events concurrently up to the limit
- `run_full_cycle()` yields progress events from concurrent scraping
- Per-platform semaphores throttle concurrent requests per platform
  </done>
</task>

<task type="auto">
  <name>Task 2: Tune HTTP connection pool and wire settings API for concurrency parameters</name>
  <files>src/api/app.py, src/api/routes/settings.py, src/api/schemas/settings.py</files>
  <action>
1. **Increase HTTP connection pool limits** (src/api/app.py):
   - Change `max_connections` from 100 to 200 (supports 10 concurrent events x 3 platforms x ~3 connections with headroom + retries)
   - Change `max_keepalive_connections` from 50 to 100
   - These are shared across all 3 platform clients

2. **Add concurrency parameters to SettingsUpdate schema** (src/api/schemas/settings.py):
   - Add optional fields to `SettingsUpdate`:
     - `max_concurrent_events: int | None = Field(None, ge=1, le=50)`
     - `betpawa_concurrency: int | None = Field(None, ge=1, le=100)`
     - `sportybet_concurrency: int | None = Field(None, ge=1, le=100)`
     - `bet9ja_concurrency: int | None = Field(None, ge=1, le=50)`
     - `bet9ja_delay_ms: int | None = Field(None, ge=0, le=100)`
     - `batch_size: int | None = Field(None, ge=10, le=200)`
   - Add matching fields to `SettingsResponse` if not already present

3. **Update settings update endpoint** (src/api/routes/settings.py):
   - In `update_settings()`, handle the new concurrency fields:
     - For each field in the update request, if not None, update the Settings model attribute
     - Follow the same pattern as existing fields (scrape_interval_minutes, etc.)

**What to avoid:**
- Do NOT change timeout settings (30s is appropriate for external API calls)
- Do NOT change retry logic — it's already well-tuned (3 attempts, 1-10s backoff)
  </action>
  <verify>
- `GET /api/settings` returns all concurrency parameters
- `PATCH /api/settings` with `{"max_concurrent_events": 15}` updates the setting
- HTTP pool limits visible in app startup (can add a debug log if needed)
  </verify>
  <done>
- HTTP connection pool increased to 200/100
- All 6 concurrency fields added to SettingsUpdate schema
- Settings update endpoint handles all concurrency parameters
- Settings response includes all concurrency values
  </done>
</task>

<task type="auto">
  <name>Task 3: Benchmark concurrent scraping and document improvements</name>
  <files>scripts/benchmark_pipeline.py</files>
  <action>
1. **Update benchmark script** (scripts/benchmark_pipeline.py):
   - Add measurement for concurrent vs sequential comparison
   - Capture `max_concurrent_events` value from settings in report
   - Report "effective events/second" throughput metric
   - Report batch processing time distribution (min/max/avg/p50/p95)

2. **Run benchmark** and capture results:
   - Run the benchmark with default max_concurrent_events=10
   - Compare batch scrape times against Phase 53 baseline (34911ms avg per batch)
   - Expected improvement: batch scrape time should drop from ~35s to ~3-5s (7-10x faster)
   - Calculate total pipeline time improvement percentage

3. **Document results** in a brief report section within the benchmark output

**What to avoid:**
- Do NOT modify the baseline report — keep it as historical reference
- Do NOT change the benchmark's core structure — extend it
  </action>
  <verify>
- Benchmark script runs successfully
- Batch scrape times significantly reduced (target: >5x improvement)
- No increase in platform errors or rate limiting
- Total pipeline time reduced from ~24 minutes baseline
  </verify>
  <done>
- Benchmark script captures concurrency metrics
- Before/after comparison shows measurable improvement in batch scrape times
- Total pipeline throughput increased
- No degradation in error rates or data quality
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Application starts without errors
- [ ] `alembic upgrade head` applies cleanly
- [ ] Full scrape cycle completes with concurrent event processing
- [ ] Batch scrape times visibly faster in logs (compare against 35s baseline)
- [ ] No rate limiting errors from external APIs
- [ ] SSE progress events still work (UI shows scrape progress)
- [ ] Write queue processes batches without errors
- [ ] Settings API returns and accepts concurrency parameters
- [ ] Benchmark script runs and shows improvement metrics
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Events processed concurrently within batches (configurable limit, default 10)
- HTTP pool sized for concurrent load (200 max connections)
- Settings API exposes all concurrency tuning parameters
- Benchmark shows measurable improvement in scrape throughput
- No regressions in data quality, error handling, or SSE streaming
- Phase 56 complete
</success_criteria>

<output>
After completion, create `.planning/phases/56-concurrency-tuning/56-01-SUMMARY.md`
</output>
