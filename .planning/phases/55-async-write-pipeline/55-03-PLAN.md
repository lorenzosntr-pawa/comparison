---
phase: 55-async-write-pipeline
plan: 03
type: execute
---

<objective>
Integrate change detection and async write queue into the scraping pipeline, then verify the improvement with benchmarks.

Purpose: Complete the decoupling of scraping from storage — the EventCoordinator updates the cache immediately but never waits for DB commits. Verify that write volume and storage latency improve significantly.
Output: Refactored EventCoordinator, queue wired into app lifecycle, benchmark results confirming improvement.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/55-async-write-pipeline/55-CONTEXT.md

# Auto-selected based on dependency graph:
@.planning/phases/55-async-write-pipeline/55-01-SUMMARY.md
@.planning/phases/55-async-write-pipeline/55-02-SUMMARY.md
@.planning/phases/54-in-memory-cache/54-02-SUMMARY.md
@.planning/phases/53-investigation-benchmarking/53-01-SUMMARY.md
@.planning/phases/53-investigation-benchmarking/BENCHMARK-BASELINE.md

# Key files:
@src/scraping/event_coordinator.py
@src/scheduling/jobs.py
@src/api/app.py
@src/caching/change_detection.py
@src/storage/write_queue.py
@src/storage/write_handler.py
@src/caching/odds_cache.py
@scripts/benchmark_pipeline.py

**Tech stack available:** asyncio, SQLAlchemy 2.0 async, structlog, perf_counter
**Established patterns:**
- Cache population from ORM models (Phase 54-02)
- Piggyback eviction on scrape schedule (Phase 54-02)
- perf_counter timing on progress events (Phase 53)
- Factory method for configurable initialization (Phase v1.7)
**Constraining decisions:**
- Phase 55 CONTEXT: Scraping never blocks on DB
- Phase 55 CONTEXT: No WebSocket, concurrency, or API changes
- Phase 54: Cache-first API serving already handles reads
- Phase 54: snapshot_to_cached_from_models() converts ORM data to cache entries
</context>

<tasks>

<task type="auto">
  <name>Task 1: Refactor EventCoordinator to use change detection and write queue</name>
  <files>src/scraping/event_coordinator.py, src/caching/warmup.py</files>
  <action>
Refactor `EventCoordinator.store_batch_results()` to decouple cache updates from DB writes. The coordinator should still handle lookups, event/competitor creation, market parsing, and reconciliation synchronously (these require the coordinator's DB session and are fast). But snapshot/market persistence moves to the write queue.

**Add write_queue parameter to EventCoordinator:**
- Add `_write_queue: AsyncWriteQueue | None` to `__init__` (optional, for backward compatibility)
- Also accept it in `from_settings()` factory method if used
- If `_write_queue` is None, fall back to current synchronous storage (keeps existing behavior for tests/on-demand scrape)

**Refactor store_batch_results() — the key change:**

After the existing processing loop (which creates events, parses markets, builds reconciliation maps), instead of creating ORM snapshot objects and calling db.flush()+db.commit():

1. **Build write data from parsed results:**
   - For each BetPawa event+bookmaker result: create `SnapshotWriteData` with event_id, bookmaker_id, scrape_run_id, raw_response, and `tuple(MarketWriteData(...))` from the parsed markets
   - For each competitor event result: create `CompetitorSnapshotWriteData` similarly

2. **Run change detection:**
   - Call `classify_batch_changes(self._odds_cache, betpawa_data, competitor_data)` to split into changed vs unchanged
   - Log change detection results: `changed_bp=X, unchanged_bp=Y, changed_comp=X, unchanged_comp=Y`

3. **Update cache immediately for ALL data (changed + unchanged):**
   - For ALL betpawa snapshots (not just changed): create CachedSnapshot via a helper and call `self._odds_cache.put_betpawa_snapshot()`
   - For ALL competitor snapshots: same with `put_competitor_snapshot()`
   - Use `snapshot_to_cached_from_data()` — a new helper in warmup.py that creates CachedSnapshot from SnapshotWriteData (not from ORM models). Use `snapshot_id=0` for changed snapshots (real ID assigned later by write handler) and the existing cached snapshot_id for unchanged ones
   - This ensures the API always serves the freshest data regardless of write queue processing

4. **Commit coordinator's session** (events, competitors, reconciliation only — no snapshots):
   - `await db.commit()` — this is fast because it only commits event/competitor records, not snapshot bulk data

5. **Enqueue write batch:**
   - Create `WriteBatch(changed_betpawa=..., changed_competitor=..., unchanged_betpawa_ids=..., unchanged_competitor_ids=..., scrape_run_id=..., batch_index=...)`
   - `await self._write_queue.enqueue(batch)`
   - This returns immediately (unless queue is full — backpressure)

6. **Add timing to progress events:**
   - Add `change_detection_ms` and `queue_enqueue_ms` fields to the storage progress event dict
   - Remove or repurpose `storage_flush_ms` and `storage_commit_ms` (these now happen asynchronously in the write handler)
   - Keep `cache_update_ms` (still synchronous)

**Create `snapshot_to_cached_from_data()` in warmup.py:**
A new helper that converts `SnapshotWriteData` / `CompetitorSnapshotWriteData` to `CachedSnapshot`. Similar to `snapshot_to_cached_from_models()` but takes plain data objects instead of ORM models.

**Fallback behavior:** If `_write_queue` is None (e.g., on-demand scrape via POST /api/scrape/event/{sr_id}), use the existing synchronous path: create ORM objects, flush, commit, update cache. This preserves backward compatibility.

**Do NOT change:** Event/competitor creation, reconciliation, market parsing logic, EventScrapeStatus recording, progress event SSE format (add fields, don't remove existing ones).
  </action>
  <verify>
Read the refactored `store_batch_results()` and verify: (1) cache is updated for ALL data before enqueue, (2) coordinator's session only commits events/reconciliation, (3) write queue receives only changed snapshots + unchanged IDs, (4) fallback to sync when write_queue is None. Run a manual scrape via the API to verify no errors: `curl -X POST http://localhost:8000/api/scrape/start`.
  </verify>
  <done>EventCoordinator uses change detection to classify snapshots, updates cache immediately for all data, enqueues only changed data to write queue. Coordinator's DB commit is lightweight (events only). Fallback to sync when queue is None.</done>
</task>

<task type="auto">
  <name>Task 2: Wire write queue into app lifecycle and scheduling</name>
  <files>src/api/app.py, src/scheduling/jobs.py</files>
  <action>
Wire the AsyncWriteQueue into the FastAPI app lifecycle and pass it to the scraping scheduler.

**In src/api/app.py lifespan:**

1. After creating OddsCache and before starting scheduler:
   ```python
   from src.storage import AsyncWriteQueue
   write_queue = AsyncWriteQueue(session_factory=async_session, maxsize=50)
   await write_queue.start()
   app.state.write_queue = write_queue
   ```

2. In the shutdown phase (after yield):
   ```python
   await write_queue.stop()  # Drains remaining items before stopping
   ```

3. Log startup: `log.info("write_queue_started")` with timing

**In src/scheduling/jobs.py:**

1. Pass `write_queue` to EventCoordinator construction:
   - The `scrape_all_platforms()` job function needs access to `write_queue` from `app.state`
   - Similar to how `odds_cache` is currently passed: retrieve from app state and pass to coordinator

2. After scrape cycle completes, log write queue stats:
   ```python
   if write_queue:
       stats = write_queue.stats()
       log.info("write_queue_post_scrape", **stats)
   ```

3. Cache eviction (already exists from Phase 54-02) remains unchanged — it runs after the scrape cycle regardless of write queue status.

**Important:** The write queue worker runs as an asyncio Task in the same event loop as the FastAPI app. It processes items continuously in the background. The scheduler enqueues batches during scraping; the worker processes them concurrently.

**Do NOT change:** Cache eviction logic, SSE progress streaming, on-demand scrape endpoint (that uses sync fallback when write_queue is None — or pass queue if desired).
  </action>
  <verify>
Start the application (`python -m uvicorn src.api.app:app`), check logs for "write_queue_started". Trigger a scrape cycle and verify: (1) logs show "write_batch_enqueued" messages during scraping, (2) logs show write handler processing messages after enqueue, (3) "write_queue_stopped" on application shutdown. Check `curl http://localhost:8000/api/scrape/runs` to verify scrape data is persisted to DB.
  </verify>
  <done>Write queue starts with app, processes batches in background during scraping, drains cleanly on shutdown. Scraping completes without waiting for DB writes. Queue stats logged after each scrape cycle.</done>
</task>

<task type="auto">
  <name>Task 3: Benchmark and verify improvements</name>
  <files>scripts/benchmark_pipeline.py</files>
  <action>
Update the existing benchmark script to measure the improvement from async writes and change detection. Run the benchmark and document results.

**Update `scripts/benchmark_pipeline.py`:**
1. Add measurement of write queue stats after scrape cycle completes:
   - Queue depth during and after scrape
   - Time from batch enqueue to write completion (if observable from logs)
2. Add measurement of change detection impact:
   - Parse structlog output to count changed vs unchanged snapshots per batch
   - Calculate write reduction percentage: `unchanged / total * 100`
3. Keep existing measurements: discovery, scraping, API latency, memory

**Run the benchmark:**
1. Ensure the app is running with the async write queue active
2. Execute: `python scripts/benchmark_pipeline.py`
3. Wait for full scrape cycle to complete AND write queue to drain
4. Capture results

**Expected improvements:**
- Storage blocking time should drop significantly (coordinator no longer waits for flush+commit)
- Write volume should decrease (only changed snapshots get INSERT'd)
- Total pipeline throughput should improve (scraping can proceed while writes happen in background)

**Document results** by adding to the benchmark output:
```
## Async Write Pipeline (Phase 55)

| Metric | Baseline (Phase 53) | After Phase 55 | Change |
|--------|---------------------|----------------|--------|
| Storage blocking time (avg/batch) | 21298ms | XXms | -XX% |
| Snapshots written per cycle | ~3900 | XX | -XX% |
| Write queue drain time | N/A | XXms | new |
| Change detection rate | N/A | XX% unchanged | new |
```

**Data integrity verification:**
- After benchmark, verify DB has correct data: `SELECT COUNT(*) FROM odds_snapshots WHERE scrape_run_id = (SELECT MAX(id) FROM scrape_runs)` — should show reduced count (only changed snapshots)
- Verify `last_confirmed_at` is set on unchanged snapshots: `SELECT COUNT(*) FROM odds_snapshots WHERE last_confirmed_at IS NOT NULL` — should be non-zero
- Verify API still returns correct data: `curl http://localhost:8000/api/events | python -m json.tool | head -20` — should show events with odds
  </action>
  <verify>
Benchmark script runs without errors. Results show: (1) reduced storage blocking time per batch, (2) write volume reduction from change detection, (3) API still serves correct data from cache, (4) DB has both new snapshots (changed) and updated timestamps (unchanged).
  </verify>
  <done>Benchmark confirms: storage blocking time reduced, write volume decreased via change detection, write queue processes asynchronously, data integrity verified (DB + cache + API consistent). Phase 55 complete.</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] Scraping completes without waiting for DB writes (coordinator returns after cache update + enqueue)
- [ ] Change detection correctly identifies unchanged snapshots (logged counts)
- [ ] Cache is updated for ALL scraped data (changed + unchanged)
- [ ] Write queue processes batches in background with retry
- [ ] DB has new snapshots for changed odds only
- [ ] DB has updated `last_confirmed_at` for unchanged snapshots
- [ ] API serves correct data from cache (unaffected by write timing)
- [ ] Application starts and stops cleanly (queue lifecycle)
- [ ] Benchmark shows measurable improvement over Phase 53 baseline
- [ ] No data loss — all changed odds eventually persisted to DB
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No errors or warnings introduced
- Scraping throughput not blocked by DB writes
- Write volume reduced via change detection
- Phase 55 complete — ready for Phase 56 (Concurrency Tuning)
  </success_criteria>

<output>
After completion, create `.planning/phases/55-async-write-pipeline/55-03-SUMMARY.md`:

# Phase 55 Plan 03: Pipeline Integration & Verification Summary

**[Substantive one-liner]**

## Accomplishments

## Files Created/Modified

## Decisions Made

## Issues Encountered

## Next Step

Phase 55 complete, ready for Phase 56 (Concurrency Tuning)
</output>
