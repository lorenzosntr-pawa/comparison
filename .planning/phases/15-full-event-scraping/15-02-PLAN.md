---
phase: 15-full-event-scraping
plan: 02
type: execute
---

<objective>
Integrate CompetitorEventScrapingService into ScrapingOrchestrator for parallel full-palimpsest scraping.

Purpose: Replace betpawa-centric scraping with parallel approach where all platforms scrape independently.
Output: Updated orchestrator that runs BetPawa + competitor scraping in parallel with proper SSE progress.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-full-event-scraping/15-CONTEXT.md
@.planning/phases/15-full-event-scraping/15-01-SUMMARY.md

**Key files:**
@src/scraping/orchestrator.py
@src/scraping/competitor_events.py
@src/api/routes/scheduler.py

**Prior decisions:**
- BetPawa flow unchanged (scrapes to events table)
- SportyBet/Bet9ja use CompetitorEventScrapingService (competitor_events table)
- Parallel scraping (not sequential with ID passing)
- Same scheduled frequency as before
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update ScrapingOrchestrator for parallel competitor scraping</name>
  <files>src/scraping/orchestrator.py</files>
  <action>
Modify scrape_with_progress() to use parallel full-palimpsest approach:

1. **Add CompetitorEventScrapingService integration:**
   - Add competitor_service parameter to __init__ (optional, for backwards compatibility)
   - `def __init__(self, ..., competitor_service: CompetitorEventScrapingService | None = None)`

2. **Update scrape_with_progress() flow:**
   ```
   OLD FLOW:
   1. Scrape BetPawa → collect SR IDs
   2. Scrape SportyBet with SR IDs filter
   3. Scrape Bet9ja with SR IDs filter

   NEW FLOW:
   1. Scrape BetPawa (unchanged - stores to events table)
   2. Scrape competitors in parallel using CompetitorEventScrapingService
      - If competitor_service provided: use it for sportybet/bet9ja
      - Else: fall back to old behavior (for backwards compat)
   ```

3. **Parallel execution:**
   - After BetPawa completes, run competitor scraping as single "Competitors" phase
   - Use competitor_service.scrape_sportybet_events() and scrape_bet9ja_events() in parallel
   - Report combined results in SSE progress

4. **SSE Progress updates:**
   - Keep existing BetPawa progress messages
   - Add "SCRAPING Competitors" phase after BetPawa
   - Report total competitor events (SportyBet + Bet9ja combined)

5. **Remove SR ID filtering logic:**
   - Remove betpawa_sportradar_ids collection and passing to _scrape_sportybet/_scrape_bet9ja
   - Those methods remain for backwards compatibility but are no longer used by scrape_with_progress when competitor_service is provided

6. **Update _store_events() for BetPawa only:**
   - When competitor_service is used, _store_events only handles Platform.BETPAWA
   - SportyBet/Bet9ja storage handled by CompetitorEventScrapingService
  </action>
  <verify>Orchestrator imports work. scrape_with_progress() accepts competitor_service parameter.</verify>
  <done>ScrapingOrchestrator runs parallel full-palimpsest scraping when competitor_service provided</done>
</task>

<task type="auto">
  <name>Task 2: Update scheduler to use new orchestrator flow</name>
  <files>src/api/routes/scheduler.py</files>
  <action>
Update the scrape endpoint to use new parallel flow:

1. **Create CompetitorEventScrapingService in endpoint:**
   - Import CompetitorEventScrapingService
   - Instantiate with clients (same clients used by orchestrator)

2. **Pass to orchestrator:**
   ```python
   competitor_service = CompetitorEventScrapingService(sportybet_client, bet9ja_client)
   orchestrator = ScrapingOrchestrator(
       sportybet_client, betpawa_client, bet9ja_client,
       competitor_service=competitor_service
   )
   ```

3. **Update SSE streaming:**
   - Ensure progress messages reflect new flow
   - "Scraping betpawa..." then "Scraping competitors..."
   - Total events = betpawa events + competitor events

4. **Update non-streaming scrape_all() if used:**
   - Same pattern: pass competitor_service to orchestrator
   - Or keep old behavior for backwards compatibility

5. **Ensure tournament discovery runs before scraping (optional):**
   - Add note in logs if competitor_tournaments is empty
   - Suggest running /discover-tournaments first
  </action>
  <verify>Start scraping via API or scheduler, observe SSE shows BetPawa then Competitors phases</verify>
  <done>Scheduler uses parallel full-palimpsest scraping flow, SSE reflects new phases</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Orchestrator accepts competitor_service parameter
- [ ] scrape_with_progress runs BetPawa, then competitors in parallel
- [ ] SSE progress shows "Scraping competitors..." phase
- [ ] competitor_events populated during scheduled scrape
- [ ] BetPawa events still stored in events table
- [ ] Old behavior preserved when competitor_service not provided
- [ ] No errors in scheduled scrape run
</verification>

<success_criteria>

- All tasks completed
- Parallel full-palimpsest scraping works end-to-end
- BetPawa → events table, Competitors → competitor_events table
- SSE progress reflects new flow
- Scheduled scraping populates all tables
- Phase 15 complete
</success_criteria>

<output>
After completion, create `.planning/phases/15-full-event-scraping/15-02-SUMMARY.md`
</output>
