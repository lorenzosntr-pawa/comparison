---
phase: 03-scraper-integration
plan: 05
type: execute
domain: fastapi
---

<objective>
Implement health check endpoint with platform connectivity verification and add platform/sport filtering to scrape endpoint.

Purpose: Enable pre-flight connectivity checks and flexible scraping filters.
Output: GET /health with per-platform status, filtering support in POST /scrape.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-scraper-integration/03-CONTEXT.md
@.planning/phases/03-scraper-integration/03-04-SUMMARY.md
@src/api/routes/health.py
@src/scraping/clients/base.py

**From 03-CONTEXT.md:**
- Health endpoint to verify scraper connectivity before running
- Filter by platform and/or by sport/league
- Football-focused but architected to support other sports later

**From 03-RESEARCH.md:**
```python
class PlatformHealth(BaseModel):
    platform: str
    status: str  # "healthy", "unhealthy", "unknown"
    response_time_ms: int | None = None
    error: str | None = None
```
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement full health check endpoint</name>
  <files>src/api/routes/health.py, src/api/schemas.py</files>
  <action>
1. Add health-related schemas to `src/api/schemas.py`:

```python
class PlatformHealth(BaseModel):
    platform: Platform
    status: str  # "healthy", "unhealthy"
    response_time_ms: int | None = None
    error: str | None = None

class HealthResponse(BaseModel):
    status: str  # "healthy" (all up), "degraded" (some up), "unhealthy" (none up)
    database: str  # "connected", "disconnected"
    platforms: list[PlatformHealth]
```

2. Rewrite `src/api/routes/health.py` with full implementation:

```python
import asyncio
import time
from fastapi import APIRouter, Request, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text

from src.api.schemas import HealthResponse, PlatformHealth
from src.api.dependencies import get_db
from src.scraping.clients import SportyBetClient, BetPawaClient, Bet9jaClient
from src.scraping.schemas import Platform

router = APIRouter(prefix="/health", tags=["health"])

@router.get("", response_model=HealthResponse)
async def health_check(
    request: Request,
    db: AsyncSession = Depends(get_db),
) -> HealthResponse:
    """
    Check connectivity to all platforms and database.

    Returns overall status:
    - "healthy": All platforms and database reachable
    - "degraded": Some platforms unreachable but at least one works
    - "unhealthy": No platforms reachable or database down
    """
    # Check database
    db_status = await _check_database(db)

    # Check platforms concurrently
    platform_checks = await asyncio.gather(
        _check_platform(Platform.SPORTYBET, SportyBetClient(request.state.sportybet_client)),
        _check_platform(Platform.BETPAWA, BetPawaClient(request.state.betpawa_client)),
        _check_platform(Platform.BET9JA, Bet9jaClient(request.state.bet9ja_client)),
        return_exceptions=True,
    )

    platforms = []
    for result in platform_checks:
        if isinstance(result, Exception):
            # Shouldn't happen since _check_platform catches exceptions
            platforms.append(PlatformHealth(
                platform=Platform.SPORTYBET,  # Unknown which failed
                status="unhealthy",
                error=str(result),
            ))
        else:
            platforms.append(result)

    # Determine overall status
    healthy_count = sum(1 for p in platforms if p.status == "healthy")
    if db_status == "disconnected":
        overall = "unhealthy"
    elif healthy_count == len(platforms):
        overall = "healthy"
    elif healthy_count > 0:
        overall = "degraded"
    else:
        overall = "unhealthy"

    return HealthResponse(status=overall, database=db_status, platforms=platforms)


async def _check_database(db: AsyncSession) -> str:
    try:
        await db.execute(text("SELECT 1"))
        return "connected"
    except Exception:
        return "disconnected"


async def _check_platform(platform: Platform, client) -> PlatformHealth:
    start = time.perf_counter()
    try:
        healthy = await client.check_health()
        elapsed_ms = int((time.perf_counter() - start) * 1000)
        return PlatformHealth(
            platform=platform,
            status="healthy" if healthy else "unhealthy",
            response_time_ms=elapsed_ms,
        )
    except Exception as e:
        elapsed_ms = int((time.perf_counter() - start) * 1000)
        return PlatformHealth(
            platform=platform,
            status="unhealthy",
            response_time_ms=elapsed_ms,
            error=str(e),
        )
```
  </action>
  <verify>python -c "from src.api.routes.health import router, health_check; print('Health endpoint ready')"</verify>
  <done>Health endpoint checks all 3 platforms + database concurrently, returns per-platform status</done>
</task>

<task type="auto">
  <name>Task 2: Add sport/competition filtering to orchestrator</name>
  <files>src/scraping/orchestrator.py, src/api/routes/scrape.py</files>
  <action>
1. Update `ScrapingOrchestrator.scrape_all()` to accept filter parameters:

```python
async def scrape_all(
    self,
    platforms: list[Platform] | None = None,
    sport_id: str | None = None,
    competition_id: str | None = None,
    include_data: bool = False,
    timeout: float = 30.0,
) -> ScrapeResult:
    """
    Scrape platforms with optional filtering.

    Args:
        platforms: Which platforms to scrape (default: all)
        sport_id: Filter to specific sport (e.g., "2" for football)
        competition_id: Filter to specific competition
        include_data: Whether to include full event data in response
        timeout: Max seconds per platform
    """
```

2. Update `_scrape_platform()` to use filters when fetching events:
   - If competition_id provided: fetch events for that competition only
   - If sport_id provided: fetch competitions for that sport, then events
   - If neither: use default (football upcoming events)

3. Update `src/api/routes/scrape.py` POST endpoint to pass filters:

```python
@router.post("", response_model=ScrapeResponse)
async def trigger_scrape(
    request: Request,
    body: ScrapeRequest = None,
    detail: str = Query(default="summary", enum=["summary", "full"]),
    timeout: int = Query(default=30, ge=5, le=300),
    db: AsyncSession = Depends(get_db),
) -> ScrapeResponse:
    # ... existing setup ...

    result = await orchestrator.scrape_all(
        platforms=body.platforms if body else None,
        sport_id=body.sport_id if body else None,
        competition_id=body.competition_id if body else None,
        include_data=(detail == "full"),
        timeout=float(timeout),
    )
    # ... rest of handler
```

Note: For this phase, filtering is passed through but may not be fully implemented for all platforms. The orchestrator should handle missing filter support gracefully (ignore filter if platform doesn't support it).
  </action>
  <verify>python -c "from src.scraping.orchestrator import ScrapingOrchestrator; import inspect; sig = inspect.signature(ScrapingOrchestrator.scrape_all); print('sport_id' in sig.parameters)"</verify>
  <done>Orchestrator accepts sport_id and competition_id parameters, scrape endpoint passes them through</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] GET /health returns per-platform connectivity status
- [ ] Health check includes database connectivity
- [ ] POST /scrape accepts sport_id and competition_id in body
- [ ] Orchestrator signature includes filter parameters
</verification>

<success_criteria>
- Health endpoint returns healthy/degraded/unhealthy based on platform connectivity
- Each platform health check runs concurrently with response time tracking
- Database connectivity included in health check
- Sport/competition filters accepted by scrape endpoint and orchestrator
</success_criteria>

<output>
After completion, create `.planning/phases/03-scraper-integration/03-05-SUMMARY.md`
</output>
