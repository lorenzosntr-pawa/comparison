---
phase: 54-in-memory-cache
plan: 03
type: execute
---

<objective>
Modify API event endpoints to serve odds data from OddsCache instead of expensive DB queries, and verify latency improvement against Phase 53 baseline.

Purpose: Deliver the actual latency reduction — replace the p50=903ms DB queries with <50ms cache lookups.
Output: GET /api/events and GET /api/events/{id} serve from cache with DB fallback; benchmark confirms improvement.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/54-in-memory-cache/54-01-SUMMARY.md
@.planning/phases/54-in-memory-cache/54-02-SUMMARY.md
@.planning/phases/53-investigation-benchmarking/BENCHMARK-BASELINE.md

# Key source files:
@src/api/routes/events.py
@src/api/app.py
@src/caching/odds_cache.py

**Tech stack available:** FastAPI dependency injection, structlog
**Established patterns:**
- `_load_latest_snapshots_for_events()` returns `dict[int, dict[int, OddsSnapshot]]`
- `_load_competitor_snapshots_for_events()` returns `dict[int, dict[str, CompetitorOddsSnapshot]]`
- `_build_inline_odds()` accesses `.markets[].betpawa_market_id`, `.betpawa_market_name`, `.line`, `.outcomes`
- `_build_matched_event()` calls `_build_inline_odds()` per bookmaker
- CachedSnapshot is duck-type compatible with OddsSnapshot (from 54-01)

**Constraining decisions:**
- Phase 53 baseline: GET /api/events p50=903ms, GET /api/events/{id} p50=35.5ms
- Cache must be optional — if not available, fall back to DB queries
- No breaking changes to API response format
</context>

<tasks>

<task type="auto">
  <name>Task 1: Modify event endpoints to serve from OddsCache with DB fallback</name>
  <files>src/api/routes/events.py</files>
  <action>
**1. Add FastAPI dependency for OddsCache:**

```python
from fastapi import Request

def get_odds_cache(request: Request) -> OddsCache | None:
    """Get OddsCache from app state, or None if not initialized."""
    return getattr(request.app.state, 'odds_cache', None)
```

**2. Create cache-aware snapshot loading functions:**

Replace direct calls to `_load_latest_snapshots_for_events()` and `_load_competitor_snapshots_for_events()` with cache-first versions:

```python
async def _load_snapshots_cached(
    event_ids: list[int],
    cache: OddsCache | None,
    db: AsyncSession,
) -> tuple[dict[int, dict[int, Any]], dict[int, dict[str, Any]]]:
    """Load snapshots from cache first, falling back to DB for misses.

    Returns:
        Tuple of (betpawa_snapshots_by_event, competitor_snapshots_by_event)
    """
    if cache is None:
        # No cache available — full DB path
        betpawa = await _load_latest_snapshots_for_events(db, event_ids)
        competitor = await _load_competitor_snapshots_for_events(db, event_ids)
        return betpawa, competitor

    # Try cache first
    betpawa = cache.get_betpawa_snapshots(event_ids)
    competitor = cache.get_competitor_snapshots(event_ids)

    # Check for cache misses
    cached_bp_ids = set(betpawa.keys())
    cached_comp_ids = set(competitor.keys())
    all_cached = cached_bp_ids | cached_comp_ids

    # Events with NO cache data at all need DB fallback
    # (An event might legitimately have no competitor data, so only consider
    # events missing from BOTH caches as potential misses)
    miss_ids = [eid for eid in event_ids if eid not in all_cached]

    if miss_ids:
        # DB fallback for misses
        db_betpawa = await _load_latest_snapshots_for_events(db, miss_ids)
        db_competitor = await _load_competitor_snapshots_for_events(db, miss_ids)
        betpawa.update(db_betpawa)
        competitor.update(db_competitor)

    return betpawa, competitor
```

**3. Modify `list_events()` endpoint (line 857):**

Add `request: Request` parameter. Get cache via `get_odds_cache(request)`.

Replace lines 1098-1099:
```python
# BEFORE:
snapshots_by_event = await _load_latest_snapshots_for_events(db, event_ids)
competitor_snapshots_by_event = await _load_competitor_snapshots_for_events(db, event_ids)

# AFTER:
cache = get_odds_cache(request)
snapshots_by_event, competitor_snapshots_by_event = await _load_snapshots_cached(
    event_ids, cache, db
)
```

**4. Modify `get_event()` endpoint (line 820):**

Add `request: Request` parameter. Same cache-first pattern:

Replace lines 845-848:
```python
# BEFORE:
snapshots_by_event = await _load_latest_snapshots_for_events(db, [event.id])
competitor_snapshots_by_event = await _load_competitor_snapshots_for_events(db, [event.id])

# AFTER:
cache = get_odds_cache(request)
snapshots_by_event, competitor_snapshots_by_event = await _load_snapshots_cached(
    [event.id], cache, db
)
```

**5. Verify duck-type compatibility:**
- `_build_inline_odds()` accesses `snapshot.markets` and iterates — CachedSnapshot.markets is a tuple of CachedMarket, which has the same attributes. Works.
- `_build_competitor_inline_odds()` — same access pattern. Works.
- `_build_event_detail_response()` calls `_build_bookmaker_market_data()` which accesses snapshot.markets and individual market attributes (betpawa_market_id, betpawa_market_name, line, outcomes, market_groups, handicap_type, handicap_home, handicap_away). CachedMarket has all of these. Works.
- `_build_event_detail_response()` also accesses `snapshot.captured_at` for snapshot_time. CachedSnapshot has this. Works.

**6. Do NOT modify the `availability='competitor'` code path** (lines 975-1085) — that queries CompetitorEvent directly and uses `_load_latest_competitor_snapshots()` which takes competitor_event_ids (not betpawa event IDs). This path is less common and the cache is keyed by betpawa_event_id. Leave this path using DB queries for now.

**7. Keep the original `_load_latest_snapshots_for_events()` and `_load_competitor_snapshots_for_events()` functions** — they're used as DB fallback and by other callers.
  </action>
  <verify>Start server, navigate to the events page in browser (http://localhost:5173). Verify events load correctly with odds data displayed. Check server logs for any errors. Test event detail page by clicking on an event.</verify>
  <done>Events list and detail pages load correctly from cache, no visual regressions, no API errors, response format unchanged</done>
</task>

<task type="auto">
  <name>Task 2: Verify latency improvement with benchmark comparison</name>
  <files>scripts/benchmark_pipeline.py</files>
  <action>
**1. Run the existing benchmark script** to measure new API latency:

```bash
cd src && python -m scripts.benchmark_pipeline
```

Or if the script runs standalone:
```bash
python scripts/benchmark_pipeline.py
```

**2. Compare results against Phase 53 baseline:**

| Metric | Baseline (Phase 53) | Target |
|--------|-------------------|--------|
| GET /api/events p50 | 903ms | <200ms |
| GET /api/events p95 | 2341ms | <500ms |
| GET /api/events/{id} p50 | 35.5ms | <30ms |

**3. Add cache hit/miss logging** to `_load_snapshots_cached()`:

```python
logger.debug(
    "Snapshot loading",
    total_requested=len(event_ids),
    cache_hits=len(all_cached),
    cache_misses=len(miss_ids),
    source="cache" if not miss_ids else "mixed",
)
```

**4. Log cache stats** after benchmark:
- Print OddsCache.stats() showing total cached events, snapshots, estimated memory
- Document results in a brief section appended to or referencing the benchmark baseline

**5. If latency targets are NOT met**, investigate:
- Check cache hit rate (should be >95% for upcoming events)
- Check if the Event query itself (not snapshot loading) is slow
- Profile the remaining DB queries (count query, event metadata query)
- Document findings for potential follow-up optimization

**6. If benchmark script needs modification** to measure cache-specific metrics, add a `--cache-stats` flag that prints OddsCache.stats() before and after API latency tests.

The benchmark script is at `scripts/benchmark_pipeline.py`. Read it to understand its API latency measurement approach before running.
  </action>
  <verify>Benchmark completes successfully, GET /api/events p50 latency reduced by at least 50% compared to baseline (903ms → <450ms)</verify>
  <done>Benchmark shows significant latency reduction for GET /api/events, cache hit rate >90%, results documented, Phase 54 complete</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] GET /api/events serves from cache (check logs for cache hits)
- [ ] GET /api/events/{id} serves from cache
- [ ] DB fallback works when cache is empty
- [ ] No visual regressions in UI
- [ ] API response format unchanged
- [ ] Benchmark shows latency improvement vs Phase 53 baseline
- [ ] No new errors or warnings
</verification>

<success_criteria>

- All tasks completed
- GET /api/events latency reduced by at least 50% (p50 from 903ms to <450ms)
- Cache hit rate >90% for upcoming events
- No breaking changes to API response format
- DB fallback works correctly for cache misses
- Phase 54 complete
</success_criteria>

<output>
After completion, create `.planning/phases/54-in-memory-cache/54-03-SUMMARY.md`

Final summary should include:
- Latency comparison (before/after)
- Cache hit rate
- Memory usage
- Any deviations from plan
</output>
