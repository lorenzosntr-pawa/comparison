---
phase: 54-in-memory-cache
plan: 01
type: execute
---

<objective>
Create the OddsCache module with data structures for storing latest odds per event/bookmaker, and implement startup warmup from DB.

Purpose: Establish the cache infrastructure that eliminates expensive GROUP BY queries on the odds_snapshots table (current GET /api/events p50=903ms).
Output: Working OddsCache class registered in app.state, pre-populated from DB on startup.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/53-investigation-benchmarking/53-01-SUMMARY.md
@.planning/phases/53-investigation-benchmarking/BENCHMARK-BASELINE.md

# Key source files:
@src/api/app.py
@src/api/routes/events.py
@src/db/models/odds.py
@src/db/models/competitor.py
@src/db/engine.py

**Tech stack available:** FastAPI, SQLAlchemy 2.0 async, structlog, Pydantic v2
**Established patterns:** Fetch-then-store, single-flush batch insert, perf_counter timing on progress events
**Constraining decisions:**
- Phase 53: API event list p50=903ms — this phase addresses it with caching
- Phase 53: Memory usage must stay reasonable (<100MB for active events)
- v1.7: AsyncSession cannot be shared across concurrent asyncio tasks
- v1.7: EventCoordinator factory method pattern (from_settings)

**Issues being addressed:** None directly from ISSUES.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create OddsCache module with data structures and lookup API</name>
  <files>src/caching/__init__.py, src/caching/odds_cache.py</files>
  <action>
Create `src/caching/` package with OddsCache class.

**Data structures** (use frozen dataclasses, NOT SQLAlchemy models — avoids detached instance issues):

```python
@dataclass(frozen=True)
class CachedMarket:
    betpawa_market_id: str
    betpawa_market_name: str
    line: float | None
    handicap_type: str | None
    handicap_home: float | None
    handicap_away: float | None
    outcomes: list[dict]  # [{name, odds, is_active}, ...]
    market_groups: list[str]

@dataclass(frozen=True)
class CachedSnapshot:
    snapshot_id: int
    event_id: int
    bookmaker_id: int
    captured_at: datetime
    markets: tuple[CachedMarket, ...]  # tuple for immutability
```

**OddsCache class:**
- Singleton-style (one instance in app.state)
- `_betpawa_snapshots: dict[int, dict[int, CachedSnapshot]]` — event_id → bookmaker_id → snapshot
- `_competitor_snapshots: dict[int, dict[str, CachedSnapshot]]` — event_id → source → snapshot
- `_event_kickoffs: dict[int, datetime]` — event_id → kickoff (for eviction)

**Lookup methods** (match the return signatures that `_build_inline_odds()` and `_build_matched_event()` expect):
- `get_betpawa_snapshots(event_ids: list[int]) -> dict[int, dict[int, CachedSnapshot]]` — same shape as `_load_latest_snapshots_for_events()` return
- `get_competitor_snapshots(event_ids: list[int]) -> dict[int, dict[str, CachedSnapshot]]` — same shape as `_load_competitor_snapshots_for_events()` return
- `get_betpawa_snapshot(event_id: int) -> dict[int, CachedSnapshot] | None`
- `get_competitor_snapshot(event_id: int) -> dict[str, CachedSnapshot] | None`

**Mutation methods:**
- `put_betpawa_snapshot(event_id: int, bookmaker_id: int, snapshot: CachedSnapshot, kickoff: datetime | None = None) -> None`
- `put_competitor_snapshot(event_id: int, source: str, snapshot: CachedSnapshot, kickoff: datetime | None = None) -> None`
- `evict_expired(cutoff: datetime) -> int` — remove events with kickoff before cutoff, return count removed
- `clear() -> None`

**Stats method:**
- `stats() -> dict` — returns {betpawa_events, competitor_events, total_snapshots, total_markets}

**CachedSnapshot must be duck-type compatible with OddsSnapshot for `_build_inline_odds()`** — the function accesses `.markets` and each market's `.betpawa_market_id`, `.betpawa_market_name`, `.line`, `.outcomes` attributes. CachedMarket matches these exactly.

**CachedSnapshot must ALSO be duck-type compatible with CompetitorOddsSnapshot for `_build_competitor_inline_odds()`** — same attribute access pattern.

Use structlog for logging cache operations. Do NOT add any external dependencies.

In `__init__.py`, export OddsCache, CachedSnapshot, CachedMarket.
  </action>
  <verify>python -c "from src.caching import OddsCache, CachedSnapshot, CachedMarket; c = OddsCache(); print(c.stats())"</verify>
  <done>OddsCache class importable, instantiable, all methods defined, stats() returns zero counts for empty cache</done>
</task>

<task type="auto">
  <name>Task 2: Implement startup warmup and register cache in app lifespan</name>
  <files>src/caching/warmup.py, src/api/app.py</files>
  <action>
Create `src/caching/warmup.py` with `warm_cache_from_db()` function:

```python
async def warm_cache_from_db(cache: OddsCache, db: AsyncSession) -> dict:
    """Load latest snapshots for upcoming events from DB into cache.

    Returns dict with warmup stats.
    """
```

**Warmup logic:**
1. Query upcoming events (kickoff > now - 2 hours) to include recently started events
2. For BetPawa snapshots: Run the same GROUP BY query currently in `_load_latest_snapshots_for_events()` but for ALL upcoming event IDs at once
3. Convert each OddsSnapshot + MarketOdds into CachedSnapshot + CachedMarket
4. For competitor snapshots: Run the same query as `_load_competitor_snapshots_for_events()` for all upcoming event IDs
5. Convert each CompetitorOddsSnapshot + CompetitorMarketOdds into CachedSnapshot + CachedMarket
6. Also store event kickoff times for eviction

**Conversion helper** (in warmup.py or odds_cache.py):
```python
def snapshot_to_cached(snapshot: OddsSnapshot | CompetitorOddsSnapshot) -> CachedSnapshot:
    """Convert a SQLAlchemy snapshot model to a CachedSnapshot."""
```

This helper extracts the plain data from the ORM object before the session closes. Must handle both OddsSnapshot (has event_id, bookmaker_id) and CompetitorOddsSnapshot (has competitor_event_id).

**Modify `src/api/app.py` lifespan:**
1. After `configure_logging()`, create OddsCache instance: `odds_cache = OddsCache()`
2. Store on app.state: `app.state.odds_cache = odds_cache`
3. Open a new DB session (using `async_session_factory`) and run `warm_cache_from_db(odds_cache, db)`
4. Log warmup results with structlog: events cached, snapshots loaded, time taken (perf_counter)
5. Place warmup AFTER `sync_settings_on_startup()` but BEFORE `yield`

**Do NOT modify the EventCoordinator or API routes in this plan** — that's plans 02 and 03.

Use `from src.db.engine import async_session_factory` for the warmup DB session (same pattern as jobs.py).
  </action>
  <verify>Start the server with `cd src && python -m uvicorn api.app:app --host 0.0.0.0 --port 8000` and check logs for cache warmup message showing event count and timing</verify>
  <done>Server starts successfully, logs show "Cache warmup complete" with event count > 0, app.state.odds_cache is populated, no errors during warmup</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from src.caching import OddsCache"` succeeds
- [ ] Server starts without errors
- [ ] Warmup log message shows events cached > 0
- [ ] `app.state.odds_cache.stats()` shows non-zero counts after startup
- [ ] No new warnings or errors in server logs
</verification>

<success_criteria>

- OddsCache module created with all data structures and methods
- Startup warmup populates cache from DB for upcoming events
- Cache registered in app.state for access by API routes
- No external dependencies added
- Memory footprint logged for monitoring
</success_criteria>

<output>
After completion, create `.planning/phases/54-in-memory-cache/54-01-SUMMARY.md`
</output>
