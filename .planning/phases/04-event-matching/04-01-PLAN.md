---
phase: 04-event-matching
plan: 01
type: execute
---

<objective>
Create the event matching service with SportRadar ID-based upsert logic and Betpawa-first metadata priority.

Purpose: Enable cross-platform event matching during scrape operations - events automatically link by SportRadar ID.
Output: EventMatchingService class with tournament/event upsert, Pydantic schemas for matched event responses.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-event-matching/04-CONTEXT.md
@.planning/phases/04-event-matching/04-RESEARCH.md
@.planning/phases/03-scraper-integration/03-06-SUMMARY.md

**Key files:**
@src/db/models/event.py
@src/db/models/sport.py
@src/db/models/odds.py
@src/scraping/schemas.py
@src/scraping/orchestrator.py

**Tech stack available:** SQLAlchemy 2.0 async, asyncpg, Pydantic v2, FastAPI
**Established patterns:**
- PostgreSQL `INSERT...ON CONFLICT DO UPDATE` via `sqlalchemy.dialects.postgresql.insert()`
- Betpawa-first metadata priority (Betpawa updates metadata, competitors don't overwrite)
- `_get_bookmaker_id` with auto-create pattern from orchestrator
- Platform enum for type-safe platform references

**Constraining decisions:**
- Phase 3: Bookmaker records auto-created on first use
- Phase 2: Events table has `sportradar_id` as unique constraint
- Phase 2: Tournament has optional `sportradar_id` (nullable, unique)

**From RESEARCH.md:**
- Use `insert().on_conflict_do_update()` for atomic upserts
- Bulk fetch by `sportradar_id IN (...)` for O(1) lookup
- First-in-wins for competitor metadata when Betpawa missing
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create event matching service with upsert logic</name>
  <files>src/matching/__init__.py, src/matching/service.py</files>
  <action>
Create `src/matching/` module with `EventMatchingService` class.

**service.py implementation:**

1. `__init__(self)` - No dependencies needed (pure data operations)

2. `async def upsert_tournament(db: AsyncSession, platform: Platform, data: dict) -> Tournament`:
   - Use `insert().on_conflict_do_update(index_elements=["sportradar_id"])`
   - If sportradar_id is None, fall back to name+sport_id unique lookup
   - For Betpawa: always update name/country
   - For competitors: insert-only, don't update existing Betpawa metadata
   - Return Tournament with id

3. `async def upsert_event(db: AsyncSession, platform: Platform, tournament_id: int, data: dict) -> Event`:
   - Use `insert().on_conflict_do_update(index_elements=["sportradar_id"])`
   - For Betpawa: update name, home_team, away_team, kickoff
   - For competitors: insert-only if new; always update kickoff (time corrections)
   - Return Event with id

4. `async def upsert_event_bookmaker(db: AsyncSession, event_id: int, bookmaker_id: int, external_event_id: str, event_url: str | None) -> EventBookmaker`:
   - Use `insert().on_conflict_do_update(index_elements=["event_id", "bookmaker_id"])`
   - Always update external_event_id and event_url (may change)
   - Return EventBookmaker

5. `async def get_events_by_sportradar_ids(db: AsyncSession, sportradar_ids: list[str]) -> dict[str, Event]`:
   - Bulk fetch: `select(Event).where(Event.sportradar_id.in_(sportradar_ids))`
   - Return dict mapping sportradar_id to Event for O(1) lookup

6. `async def process_scraped_events(db: AsyncSession, platform: Platform, bookmaker_id: int, events: list[dict]) -> ProcessingResult`:
   - Orchestration method that calls upsert_tournament, upsert_event, upsert_event_bookmaker
   - Track counts: new_events, updated_events, new_tournaments

**Import from sqlalchemy.dialects.postgresql import insert** for upsert pattern.

**__init__.py:** Export EventMatchingService
  </action>
  <verify>python -c "from src.matching import EventMatchingService; print('OK')"</verify>
  <done>EventMatchingService importable with all upsert methods defined</done>
</task>

<task type="auto">
  <name>Task 2: Create Pydantic schemas for matched events</name>
  <files>src/matching/schemas.py</files>
  <action>
Create Pydantic v2 schemas for API responses.

**schemas.py:**

1. `ProcessingResult(BaseModel)`:
   - new_events: int
   - updated_events: int
   - new_tournaments: int

2. `BookmakerOdds(BaseModel)`:
   - bookmaker_slug: str
   - bookmaker_name: str
   - external_event_id: str
   - event_url: str | None
   - has_odds: bool = False (placeholder for future)

3. `MatchedEvent(BaseModel)`:
   - id: int
   - sportradar_id: str
   - name: str
   - home_team: str
   - away_team: str
   - kickoff: datetime
   - tournament_id: int
   - tournament_name: str
   - sport_name: str
   - bookmakers: list[BookmakerOdds]
   - created_at: datetime

4. `MatchedEventList(BaseModel)`:
   - events: list[MatchedEvent]
   - total: int
   - page: int = 1
   - page_size: int = 50

5. `UnmatchedEvent(BaseModel)`:
   - id: int
   - sportradar_id: str
   - name: str
   - kickoff: datetime
   - platform: str (which platform has it)
   - missing_on: list[str] (platforms that don't have it)

Use `model_config = ConfigDict(from_attributes=True)` for ORM compatibility.
  </action>
  <verify>python -c "from src.matching.schemas import MatchedEvent, ProcessingResult; print('OK')"</verify>
  <done>All Pydantic schemas importable and type-correct</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from src.matching import EventMatchingService"` succeeds
- [ ] `python -c "from src.matching.schemas import MatchedEvent, ProcessingResult"` succeeds
- [ ] No import errors or type issues
</verification>

<success_criteria>

- EventMatchingService with upsert_tournament, upsert_event, upsert_event_bookmaker methods
- ProcessingResult, MatchedEvent, UnmatchedEvent schemas defined
- All imports work without errors
</success_criteria>

<output>
After completion, create `.planning/phases/04-event-matching/04-01-SUMMARY.md`
</output>
