---
phase: 62-historical-data-api
plan: 01
type: execute
---

<objective>
Create Pydantic response schemas for historical data APIs and add database index for efficient queries.

Purpose: Establish the data contracts and query optimization needed for historical odds/margin visualization.
Output: Response schemas in matching/schemas.py, composite index migration for market_odds table.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/60-investigation-schema-design/DISCOVERY.md

# Key files:
@src/matching/schemas.py
@src/db/models/odds.py

# Query patterns from Phase 60 DISCOVERY:
# - Odds trend: JOIN odds_snapshots + market_odds WHERE event_id=? AND market_id=? ORDER BY captured_at
# - Need composite index on (snapshot_id, betpawa_market_id) for efficient JOINs

# Established patterns:
# - Pydantic v2 with ConfigDict(from_attributes=True)
# - Margin calculation: (sum(1/odds) - 1) * 100
# - Existing schemas: OutcomeOdds, MarketOddsDetail already handle outcomes/margin
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create historical data Pydantic schemas</name>
  <files>src/matching/schemas.py</files>
  <action>
Add new response schemas for historical data API endpoints at the end of the file:

1. `HistoricalSnapshot` - Snapshot metadata for list view:
   - id: int
   - captured_at: datetime
   - bookmaker_slug: str
   - bookmaker_name: str
   - market_count: int

2. `SnapshotHistoryResponse` - Response for snapshot list endpoint:
   - event_id: int
   - snapshots: list[HistoricalSnapshot]
   - total: int

3. `OddsHistoryPoint` - Single point in odds time series:
   - captured_at: datetime
   - outcomes: list[OutcomeOdds] (reuse existing schema)
   - margin: float | None

4. `OddsHistoryResponse` - Full odds history for a market:
   - event_id: int
   - bookmaker_slug: str
   - bookmaker_name: str
   - market_id: str
   - market_name: str
   - line: float | None
   - history: list[OddsHistoryPoint]

5. `MarginHistoryPoint` - Single margin point:
   - captured_at: datetime
   - margin: float | None

6. `MarginHistoryResponse` - Margin-only history for charts:
   - event_id: int
   - bookmaker_slug: str
   - bookmaker_name: str
   - market_id: str
   - market_name: str
   - line: float | None
   - history: list[MarginHistoryPoint]

Use ConfigDict(from_attributes=True) where ORM mapping is needed.
  </action>
  <verify>python -c "from src.matching.schemas import HistoricalSnapshot, SnapshotHistoryResponse, OddsHistoryPoint, OddsHistoryResponse, MarginHistoryPoint, MarginHistoryResponse; print('Schemas imported successfully')"</verify>
  <done>All 6 historical data schemas defined and importable without errors</done>
</task>

<task type="auto">
  <name>Task 2: Add composite index migration for market history queries</name>
  <files>src/db/migrations/versions/xxx_add_market_history_index.py</files>
  <action>
Create Alembic migration to add composite index for efficient market history queries:

```bash
cd src/db && alembic revision -m "add_market_history_index"
```

In the generated migration file:

upgrade():
```python
op.create_index(
    'idx_market_odds_snapshot_market',
    'market_odds',
    ['snapshot_id', 'betpawa_market_id'],
    unique=False
)
```

downgrade():
```python
op.drop_index('idx_market_odds_snapshot_market', table_name='market_odds')
```

This composite index optimizes the JOIN pattern:
```sql
SELECT s.captured_at, m.outcomes
FROM odds_snapshots s
JOIN market_odds m ON m.snapshot_id = s.id
WHERE s.event_id = ? AND m.betpawa_market_id = ?
ORDER BY s.captured_at;
```

The index allows efficient lookup by snapshot_id first (from the JOIN), then filter by market_id.
  </action>
  <verify>cd src/db && alembic upgrade head && alembic current</verify>
  <done>Migration created and applied successfully, index exists in database</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] All 6 Pydantic schemas defined in src/matching/schemas.py
- [ ] Schemas import without errors
- [ ] Alembic migration created and applied
- [ ] Index idx_market_odds_snapshot_market exists in database
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No import errors or type issues
- Database migration applied cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/62-historical-data-api/62-01-SUMMARY.md`
</output>
