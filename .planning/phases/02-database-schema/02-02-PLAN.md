---
phase: 02-database-schema
plan: 02
type: execute
---

<objective>
Create odds snapshot and operational tracking models with partitioning support.

Purpose: Define the time-series data models that store historical odds snapshots and track scraping operations.
Output: OddsSnapshot (partitioned), MarketOdds, ScrapeRun, and ScrapeError models ready for 30-day retention.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-database-schema/02-RESEARCH.md
@.planning/phases/02-database-schema/02-CONTEXT.md
@.planning/phases/02-database-schema/02-01-PLAN.md

**From 02-01:** Base, engine, async_session_factory, Sport, Tournament, Bookmaker, Event, EventBookmaker

**From RESEARCH.md - MUST follow:**
- Partitioned table pattern for OddsSnapshot (PARTITION BY RANGE on captured_at)
- B-tree indexes on foreign keys
- BRIN index on captured_at (naturally time-ordered data)
- Composite index on (event_id, captured_at DESC) for common query pattern
- JSONB only for raw_response, normalize frequently-queried fields

**From CONTEXT.md:**
- Store all 111+ market types
- Track failure history for recurring issues
- Flag data as potentially stale when scrapes fail
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create OddsSnapshot and MarketOdds models</name>
  <files>src/db/models/odds.py</files>
  <action>
Create odds snapshot models in `src/db/models/odds.py`:

1. **OddsSnapshot model** (parent table for partitioning):
```python
# Table will be partitioned by captured_at in the migration
# SQLAlchemy model defines structure, Alembic migration handles partitioning

class OddsSnapshot(Base):
    __tablename__ = "odds_snapshots"
    __table_args__ = (
        Index("idx_snapshots_event", "event_id"),
        Index("idx_snapshots_bookmaker", "bookmaker_id"),
        Index("idx_snapshots_event_time", "event_id", "captured_at", postgresql_ops={"captured_at": "DESC"}),
        # Note: BRIN index added in raw SQL migration, not here
    )

- id: Mapped[int] primary_key (BIGINT for partitioned tables - use BigInteger)
- event_id: Mapped[int] ForeignKey to events.id, nullable=False
- bookmaker_id: Mapped[int] ForeignKey to bookmakers.id, nullable=False
- captured_at: Mapped[datetime] nullable=False, server_default=func.now()
- scrape_run_id: Mapped[int | None] ForeignKey to scrape_runs.id (which scrape produced this)
- raw_response: Mapped[dict | None] (JSONB - full API response for debugging)
- event: relationship to Event
- bookmaker: relationship to Bookmaker
- markets: relationship to MarketOdds
```

Use `from sqlalchemy import BigInteger, JSON` and `mapped_column(BigInteger, primary_key=True)` for id.
Use `mapped_column(JSON)` for raw_response (SQLAlchemy maps to JSONB on PostgreSQL).

2. **MarketOdds model** (individual market odds per snapshot):
```python
class MarketOdds(Base):
    __tablename__ = "market_odds"
    __table_args__ = (
        Index("idx_market_odds_snapshot", "snapshot_id"),
        Index("idx_market_odds_market", "betpawa_market_id"),
    )

- id: Mapped[int] primary_key (BigInteger)
- snapshot_id: Mapped[int] ForeignKey to odds_snapshots.id, nullable=False (BigInteger)
- betpawa_market_id: Mapped[str] nullable=False (e.g., "3743" for 1X2)
- betpawa_market_name: Mapped[str] nullable=False (e.g., "1X2 - FT")
- line: Mapped[float | None] (for Over/Under markets)
- handicap_type: Mapped[str | None] (e.g., "european", "asian")
- handicap_home: Mapped[float | None]
- handicap_away: Mapped[float | None]
- outcomes: Mapped[dict] (JSONB - list of {name, odds, is_active})
- snapshot: relationship to OddsSnapshot
```

Note: `outcomes` is JSONB because outcome structure varies by market type. Example:
`[{"name": "1", "odds": 1.85, "is_active": true}, {"name": "X", "odds": 3.40, "is_active": true}, {"name": "2", "odds": 4.20, "is_active": true}]`
  </action>
  <verify>python -c "from src.db.models.odds import OddsSnapshot, MarketOdds; print('Odds models OK')"</verify>
  <done>OddsSnapshot and MarketOdds models defined with indexes and relationships</done>
</task>

<task type="auto">
  <name>Task 2: Create ScrapeRun and ScrapeError models</name>
  <files>src/db/models/scrape.py, src/db/models/__init__.py</files>
  <action>
Create operational tracking models in `src/db/models/scrape.py`:

1. **ScrapeRun model** (tracks each scraping execution):
```python
from enum import StrEnum

class ScrapeStatus(StrEnum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    PARTIAL = "partial"  # Some bookmakers succeeded, some failed
    FAILED = "failed"

class ScrapeRun(Base):
    __tablename__ = "scrape_runs"
    __table_args__ = (
        Index("idx_scrape_runs_status", "status"),
        Index("idx_scrape_runs_started", "started_at"),
    )

- id: Mapped[int] primary_key
- status: Mapped[ScrapeStatus] default=ScrapeStatus.PENDING
- started_at: Mapped[datetime] server_default=func.now()
- completed_at: Mapped[datetime | None]
- events_scraped: Mapped[int] default=0
- events_failed: Mapped[int] default=0
- trigger: Mapped[str | None] (e.g., "scheduled", "manual", "webhook")
- errors: relationship to ScrapeError
- snapshots: relationship to OddsSnapshot
```

2. **ScrapeError model** (tracks individual scrape failures):
```python
class ScrapeError(Base):
    __tablename__ = "scrape_errors"
    __table_args__ = (
        Index("idx_scrape_errors_run", "scrape_run_id"),
        Index("idx_scrape_errors_bookmaker", "bookmaker_id"),
    )

- id: Mapped[int] primary_key
- scrape_run_id: Mapped[int] ForeignKey to scrape_runs.id
- bookmaker_id: Mapped[int | None] ForeignKey to bookmakers.id (None if global error)
- event_id: Mapped[int | None] ForeignKey to events.id (None if bookmaker-level error)
- error_type: Mapped[str] (e.g., "timeout", "rate_limit", "parse_error", "network")
- error_message: Mapped[str]
- occurred_at: Mapped[datetime] server_default=func.now()
- scrape_run: relationship to ScrapeRun
- bookmaker: relationship to Bookmaker
- event: relationship to Event
```

3. Update `src/db/models/__init__.py`:
   - Add imports and exports for: OddsSnapshot, MarketOdds, ScrapeRun, ScrapeError, ScrapeStatus
   - Full export list: Sport, Tournament, Bookmaker, Event, EventBookmaker, OddsSnapshot, MarketOdds, ScrapeRun, ScrapeError, ScrapeStatus
  </action>
  <verify>python -c "from src.db.models import OddsSnapshot, MarketOdds, ScrapeRun, ScrapeError, ScrapeStatus; print('All models OK')"</verify>
  <done>All 9 models importable from src.db.models, operational tracking ready</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from src.db.models import OddsSnapshot, MarketOdds, ScrapeRun, ScrapeError"` succeeds
- [ ] OddsSnapshot has BigInteger primary key (for partitioning compatibility)
- [ ] MarketOdds.outcomes uses JSON type for JSONB storage
- [ ] ScrapeStatus enum has all 5 states
- [ ] All indexes defined in __table_args__
</verification>

<success_criteria>

- OddsSnapshot model ready for partitioning (BigInteger PK, proper indexes)
- MarketOdds stores normalized market data with JSONB outcomes
- ScrapeRun and ScrapeError enable operational monitoring
- All models export cleanly from src.db.models
- Ready for Alembic migration in Plan 03
</success_criteria>

<output>
After completion, create `.planning/phases/02-database-schema/02-02-SUMMARY.md`
</output>
