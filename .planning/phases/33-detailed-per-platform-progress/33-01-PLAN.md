---
phase: 33-detailed-per-platform-progress
type: execute
---

<objective>
Enrich orchestrator progress events with real per-platform counts and timing, and display per-bookmaker sub-steps in the live progress UI.

Purpose: Make scraping transparent — see which bookmaker is active, how many events each found, and how long each took.
Output: Per-platform progress events from backend, inline sub-step display in frontend with real counts and elapsed time.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/33-detailed-per-platform-progress/33-CONTEXT.md
@.planning/phases/31-backend-heartbeat/31-01-SUMMARY.md
@.planning/phases/32-connection-loss-logging/32-01-SUMMARY.md

# Key source files:
@src/scraping/schemas.py
@src/scraping/orchestrator.py
@src/api/routes/scrape.py
@web/src/features/scrape-runs/components/live-progress.tsx

**Tech stack available:** FastAPI, SSE streaming, structlog, React 19, TanStack Query v5, shadcn/ui, Tailwind v4
**Established patterns:** ScrapeProgress model for SSE events, _emit_phase() for progress emission, ProgressBroadcaster pub/sub, PlatformProgress tracking in frontend

**Constraining decisions:**
- Phase 31: Stale detection uses ScrapePhaseLog for timing audit
- Phase 32: CONNECTION_FAILED status and subscriber count monitoring between platform completions
- AsyncSession cannot be shared across concurrent tasks — competitor scrapes run sequentially

**Current state of progress events:**
- Orchestrator uses `_scrape_with_competitor_service()` flow (lines 313-570)
- BetPawa gets its own SCRAPING → STORING → COMPLETED events with platform="betpawa"
- Competitors are lumped: platform=None with message "Scraping competitors (SportyBet + Bet9ja)..."
- No per-platform progress events for SportyBet or Bet9ja during competitor phase
- Frontend PlatformProgress tracks phase/eventsCount/isComplete per platform but only BetPawa gets real data
- Frontend shows "60%" width for active platform (hardcoded), no real counts for competitors
</context>

<tasks>

<task type="auto">
  <name>Task 1: Emit per-platform progress events for each competitor in orchestrator</name>
  <files>src/scraping/orchestrator.py, src/scraping/schemas.py</files>
  <action>
In `_scrape_with_competitor_service()` (orchestrator.py lines 454-548), the competitor phase currently emits a single "Scraping competitors" event with platform=None, then scrapes SportyBet and Bet9ja sequentially without per-platform events.

**Changes to orchestrator.py:**

1. Before SportyBet scrape (after line 479), emit a SCRAPING event with platform=Platform.SPORTYBET:
   - message: "Scraping sportybet..."
   - current=1, total=total_phases (keep overall phase indexing)
   - Record sportybet_start_time = time.perf_counter()

2. After SportyBet completes (after line 486), emit a COMPLETED event with platform=Platform.SPORTYBET:
   - events_count=sportybet_events
   - duration_ms=sportybet_duration_ms
   - Also log phase history for SportyBet

3. If SportyBet fails (in except block line 487-488), emit a FAILED event with platform=Platform.SPORTYBET:
   - elapsed_ms from sportybet_start_time

4. Same pattern for Bet9ja (lines 490-499):
   - SCRAPING event before, COMPLETED/FAILED event after
   - With platform=Platform.BET9JA, real counts and timing

5. Keep the existing overall competitor COMPLETED event (lines 512-520) as-is — it serves as the phase-level completion marker.

6. Add `elapsed_ms` field to the SCRAPING events: set elapsed_ms=0 on start events so the frontend can calculate running time from timestamp if needed.

**Do NOT change ScrapeProgress schema** — all needed fields (platform, phase, events_count, duration_ms, elapsed_ms) already exist.

**Do NOT change the connection loss detection** — it checks subscriber_count between platform completions in scrape.py, not in the orchestrator. The new per-platform events are emitted within the existing competitor phase and don't affect that check.

**Important:** Also emit per-platform events in the initializing phase — change the competitor SCRAPING event (line 463-469) to still emit but keep platform=None as the "phase start" marker. The new per-platform events go inside the try block alongside the actual scrapes.
  </action>
  <verify>
Start a scrape via the API and watch the SSE stream:
```bash
curl -N http://localhost:8000/api/scrape/stream 2>/dev/null | head -20
```
Verify that the stream contains events with platform="sportybet" and platform="bet9ja" (not just platform=null and platform="betpawa"). Each competitor should have at least a SCRAPING and COMPLETED event with events_count and duration_ms populated.
  </verify>
  <done>SSE stream emits per-platform SCRAPING and COMPLETED events for sportybet and bet9ja with real event counts and duration_ms values</done>
</task>

<task type="auto">
  <name>Task 2: Display per-platform sub-steps with counts and elapsed time in frontend</name>
  <files>web/src/features/scrape-runs/components/live-progress.tsx</files>
  <action>
Update LiveProgressPanel to show real per-platform data now that the backend emits it:

1. **Extend PlatformProgress interface** (line 18-23):
   - Add `durationMs: number | null` to track completed platform timing
   - Add `startedAt: number | null` (Date.now() when first SCRAPING event received)

2. **Update the onmessage handler** (lines 88-98):
   - When receiving a platform-specific event, also capture:
     - `durationMs` from data.duration_ms on COMPLETED events
     - `startedAt` = Date.now() on first SCRAPING event for that platform (only if startedAt is null)

3. **Update per-platform display** (lines 241-284):
   - Show real event count: `{progress.eventsCount} events` (already shown, but now populated for all platforms)
   - Show timing: after platform completes, show duration like `(3.2s)` from durationMs
   - While platform is active, show live elapsed time from startedAt using a simple interval or just show "..." — do NOT add a setInterval timer (over-engineering). Simply show the phase name instead.
   - Format: "SportyBet: 142 events (3.2s)" when complete, "SportyBet: scraping..." when active

4. **Fix progress bar width calculation** (lines 277-280):
   - Currently hardcoded to 60% for active. Instead, keep it at 60% for active (we don't have a total to calculate against — that's fine). The real improvement is showing counts and timing, not the bar width.

5. **Do NOT add expanding/collapsing sub-steps** — that's over-engineering for this phase. The existing per-platform rows already show each bookmaker. Just make the data real instead of placeholder.
  </action>
  <verify>
Run the frontend dev server and trigger a scrape. Verify in the Live Scrape Progress panel:
1. Each platform (BetPawa, SportyBet, Bet9ja) shows real event counts as they complete
2. Completed platforms show duration in seconds (e.g., "142 events (3.2s)")
3. Active platform shows a spinner with phase indicator
4. All three platforms transition from pending → active → complete with real data
  </verify>
  <done>Live progress panel shows real per-platform event counts and completion times for all three bookmakers</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] SSE stream contains per-platform events for sportybet and bet9ja (not just betpawa)
- [ ] Each competitor platform event includes events_count and duration_ms
- [ ] Frontend displays real counts and timing for all three platforms
- [ ] No TypeScript errors (`cd web && npx tsc --noEmit`)
- [ ] Backend still runs without errors
- [ ] Connection loss detection still works (subscriber_count check unaffected)
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Per-platform progress shows real counts and timing in the UI
- No regressions to existing scraping functionality
- No regressions to connection loss detection (Phase 32)
</success_criteria>

<output>
After completion, create `.planning/phases/33-detailed-per-platform-progress/33-01-SUMMARY.md`
</output>
