---
phase: 108-read-path-cache
plan: 01
type: execute
---

<objective>
Update cache warmup and API DB fallback queries to read from market_odds_current instead of legacy snapshot tables.

Purpose: Complete the read path migration for the market-level storage architecture, enabling 95% storage reduction.
Output: All API reads use market_odds_current; warmup loads from new table; legacy snapshot tables no longer queried.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase summaries (market-level storage architecture)
@.planning/phases/105-investigation-schema-design/105-01-SUMMARY.md
@.planning/phases/106-schema-migration/106-01-SUMMARY.md
@.planning/phases/107-write-path-changes/107-01-SUMMARY.md
@.planning/phases/107-write-path-changes/107-02-SUMMARY.md

# Key source files to modify
@src/caching/warmup.py
@src/caching/odds_cache.py
@src/api/routes/events.py

# New schema (from Phase 106)
@src/db/models/market_odds.py

**Phase 105 Key Findings:**
- market_odds_current uses (event_id, bookmaker_slug, betpawa_market_id, line) as unique key
- All bookmakers unified via bookmaker_slug ('betpawa', 'sportybet', 'bet9ja')
- No snapshot_id needed - each row IS the current state

**Current Read Path (to be replaced):**
- warmup.py: Complex GROUP BY subquery to get MAX(OddsSnapshot.id) per event+bookmaker
- events.py: _load_latest_snapshots_for_events() queries odds_snapshots with GROUP BY
- events.py: _load_competitor_snapshots_for_events() queries through CompetitorEvent â†’ CompetitorOddsSnapshot

**New Read Path (simplified):**
- warmup.py: Simple query to market_odds_current WHERE event_id IN (...)
- events.py: Same simple queries, unified table for all bookmakers
- No GROUP BY needed - table IS the current state
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update cache warmup to load from market_odds_current</name>
  <files>src/caching/warmup.py</files>
  <action>
Replace the complex OddsSnapshot/CompetitorOddsSnapshot queries in warm_cache_from_db() with a simpler market_odds_current query:

1. Query all market_odds_current rows WHERE event_id IN (upcoming_event_ids)
2. Group results by (event_id, bookmaker_slug) using a dict
3. For each group, build a CachedSnapshot:
   - snapshot_id=0 (not used in new schema)
   - event_id=row.event_id
   - bookmaker_id=0 for competitors, or fetch from bookmakers table for betpawa
   - captured_at=max(last_updated_at) across markets in group
   - last_confirmed_at=max(last_confirmed_at) across markets in group
   - markets=tuple of CachedMarket objects built from rows
4. Split into _betpawa_snapshots (bookmaker_slug='betpawa') and _competitor_snapshots (bookmaker_slug in 'sportybet','bet9ja')
5. Import MarketOddsCurrent from src.db.models.market_odds

Keep existing Event query for kickoff_map (unchanged).

Do NOT remove the existing snapshot_to_cached() helpers - they're still used by event_coordinator for the write path during dual-write period.
  </action>
  <verify>
python -c "from src.caching.warmup import warm_cache_from_db; print('Import OK')"
  </verify>
  <done>warm_cache_from_db() queries market_odds_current instead of odds_snapshots/competitor_odds_snapshots</done>
</task>

<task type="auto">
  <name>Task 2: Update events.py DB fallback queries</name>
  <files>src/api/routes/events.py</files>
  <action>
Update the DB fallback functions to query market_odds_current:

1. **_load_latest_snapshots_for_events()**:
   - Query: SELECT * FROM market_odds_current WHERE event_id IN (:ids) AND bookmaker_slug = 'betpawa'
   - Group by event_id
   - Build CachedSnapshot objects (reuse warmup pattern)
   - Return dict[int, dict[int, CachedSnapshot]] where inner dict uses bookmaker_id from bookmakers table lookup
   - Import MarketOddsCurrent from src.db.models.market_odds
   - Import CachedSnapshot, CachedMarket from src.caching.odds_cache

2. **_load_competitor_snapshots_for_events()**:
   - Query: SELECT * FROM market_odds_current WHERE event_id IN (:ids) AND bookmaker_slug IN ('sportybet', 'bet9ja')
   - Group by (event_id, bookmaker_slug)
   - Build CachedSnapshot objects
   - Return dict[int, dict[str, CachedSnapshot]] where inner dict uses bookmaker_slug as key
   - No need to go through CompetitorEvent anymore - event_id is already the BetPawa event ID

3. Both functions now return CachedSnapshot objects instead of ORM models, matching what cache.get_*_snapshots() returns. This ensures _build_inline_odds() and _build_competitor_inline_odds() work consistently.

4. Helper function to build CachedSnapshot from grouped MarketOddsCurrent rows:
   ```python
   def _build_cached_snapshot_from_current(
       event_id: int,
       bookmaker_id: int,
       markets: list[MarketOddsCurrent],
   ) -> CachedSnapshot:
       cached_markets = [
           CachedMarket(
               betpawa_market_id=m.betpawa_market_id,
               betpawa_market_name=m.betpawa_market_name,
               line=m.line,
               handicap_type=m.handicap_type,
               handicap_home=m.handicap_home,
               handicap_away=m.handicap_away,
               outcomes=m.outcomes if isinstance(m.outcomes, list) else [],
               market_groups=m.market_groups,
               unavailable_at=m.unavailable_at,
           )
           for m in markets
       ]
       # Use max timestamps from markets
       last_updated = max(m.last_updated_at for m in markets)
       last_confirmed = max(m.last_confirmed_at for m in markets)
       return CachedSnapshot(
           snapshot_id=0,
           event_id=event_id,
           bookmaker_id=bookmaker_id,
           captured_at=last_updated,
           last_confirmed_at=last_confirmed,
           markets=tuple(cached_markets),
       )
   ```

5. Update imports at top of file to add MarketOddsCurrent and CachedSnapshot/CachedMarket.

Note: Keep OddsSnapshot and CompetitorOddsSnapshot imports for now - they may still be used elsewhere in the file or during transition.
  </action>
  <verify>
python -c "from src.api.routes.events import router; print('Import OK')"
  </verify>
  <done>_load_latest_snapshots_for_events() and _load_competitor_snapshots_for_events() query market_odds_current and return CachedSnapshot objects</done>
</task>

<task type="auto">
  <name>Task 3: Verify API responses</name>
  <files>None (verification only)</files>
  <action>
Start the server and verify API responses are correct:

1. Start dev server: cd server && python -m uvicorn src.main:app --reload --port 8000

2. Test events list endpoint (with existing data):
   curl http://localhost:8000/api/events | python -m json.tool | head -50
   - Verify response has events with inline_odds containing outcomes
   - Check that snapshot_time is present

3. Test single event detail endpoint:
   curl "http://localhost:8000/api/events/1" | python -m json.tool | head -100
   - Verify bookmakers array has odds data
   - Verify markets are populated

4. Check warmup logs on server startup:
   - Look for "cache.warmup.complete" log with counts
   - Verify betpawa_snapshots and competitor_snapshots counts are non-zero

5. If any errors occur, check server logs for stack traces and fix.
  </action>
  <verify>curl -s http://localhost:8000/api/events | python -m json.tool | grep -q "inline_odds" && echo "OK"</verify>
  <done>API endpoints return valid responses with odds data from new schema</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] warmup.py imports and queries market_odds_current
- [ ] events.py imports and queries market_odds_current
- [ ] Server starts without import errors
- [ ] GET /api/events returns events with inline_odds
- [ ] GET /api/events/{id} returns event detail with markets
- [ ] Cache warmup logs show non-zero snapshot counts
- [ ] No references to odds_snapshots or competitor_odds_snapshots in read path
</verification>

<success_criteria>
- All read path queries use market_odds_current
- API responses unchanged (same structure and data)
- Cache warmup faster due to simpler queries
- Legacy snapshot tables only used by write path (dual-write period)
</success_criteria>

<output>
After completion, create `.planning/phases/108-read-path-cache/108-01-SUMMARY.md`:

# Phase 108 Plan 01: Read Path & Cache Summary

**[One-liner describing what shipped]**

## Performance

- **Duration:** X min
- **Tasks:** 3
- **Files modified:** 2

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Task Commits

1. **Task 1: ...** - `{hash}` (feat)
2. **Task 2: ...** - `{hash}` (feat)
3. **Task 3: ...** - No commit (verification only)

## Files Created/Modified

- `src/caching/warmup.py` - Simplified query using market_odds_current
- `src/api/routes/events.py` - Updated fallback queries for new schema

## Decisions Made

[Any decisions made during implementation]

## Deviations from Plan

[Any changes from the original plan]

## Issues Encountered

[Problems and resolutions]

## Next Phase Readiness

- Phase 109 ready: Historical API can use market_odds_history
- Read path complete, write path complete
- Only cleanup (retention, legacy table removal) remains
</output>
