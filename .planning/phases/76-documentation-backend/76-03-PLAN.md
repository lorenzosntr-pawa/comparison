---
phase: 76-documentation-backend
plan: 03
type: execute
---

<objective>
Add comprehensive docstrings to orchestration layer modules including scraping, scheduling, caching, and storage.

Purpose: Document the runtime behavior and data flow through the scraping pipeline.
Output: All orchestration layer Python files with PEP 257 compliant docstrings for modules, classes, and functions.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/codebase/CONVENTIONS.md
@.planning/codebase/ARCHITECTURE.md

**Documentation standard (from CONVENTIONS.md):**
- Module docstring at file start
- Function docstrings with `Args:`, `Returns:`, `Raises:` sections
- Follow PEP 257 conventions
- Document async patterns and concurrency considerations

**Files to document:**

Scraping Layer (15 files):
- src/scraping/broadcaster.py
- src/scraping/clients/base.py
- src/scraping/clients/bet9ja.py
- src/scraping/clients/betpawa.py
- src/scraping/clients/sportybet.py
- src/scraping/clients/__init__.py
- src/scraping/competitor_events.py
- src/scraping/event_coordinator.py
- src/scraping/exceptions.py
- src/scraping/logging.py
- src/scraping/schemas/coordinator.py
- src/scraping/schemas/__init__.py
- src/scraping/schemas.py
- src/scraping/tournament_discovery.py
- src/scraping/__init__.py

Support Services (16 files):
- src/caching/change_detection.py
- src/caching/odds_cache.py
- src/caching/warmup.py
- src/caching/__init__.py
- src/scheduling/jobs.py
- src/scheduling/scheduler.py
- src/scheduling/stale_detection.py
- src/scheduling/__init__.py
- src/matching/schemas.py
- src/matching/service.py
- src/matching/__init__.py
- src/services/cleanup.py
- src/services/__init__.py
- src/storage/write_handler.py
- src/storage/write_queue.py
- src/storage/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Document scraping layer</name>
  <files>src/scraping/broadcaster.py, src/scraping/clients/base.py, src/scraping/clients/bet9ja.py, src/scraping/clients/betpawa.py, src/scraping/clients/sportybet.py, src/scraping/competitor_events.py, src/scraping/event_coordinator.py, src/scraping/exceptions.py, src/scraping/logging.py, src/scraping/schemas/coordinator.py, src/scraping/schemas.py, src/scraping/tournament_discovery.py</files>
  <action>
Add or enhance docstrings for all scraping layer files:

1. **EventCoordinator** - The core orchestration class:
   - Class docstring explaining event-centric parallel scraping architecture
   - Document from_settings() factory method
   - Document scrape_batch() async generator pattern
   - Document store_batch_results() dual-path (async queue vs sync)

2. **HTTP clients** (bet9ja.py, betpawa.py, sportybet.py):
   - Document rate limiting and retry behavior
   - Document response parsing and error handling
   - Explain platform-specific quirks (headers, delays)

3. **Broadcaster** - Progress event streaming:
   - Document ProgressBroadcaster pattern
   - Explain subscriber registration/unregistration
   - Document broadcast_progress() async method

4. **Tournament discovery** - Cross-platform event discovery:
   - Document TournamentDiscoveryService class
   - Explain discover_all() method

5. **Schemas** - Scraping data structures:
   - Document EventTarget, ScrapeBatch, ScrapeStatus
   - Explain frozen dataclass pattern for write queue

Format for async methods:
```python
async def scrape_batch(
    self,
    batch: ScrapeBatch,
    session: AsyncSession,
) -> AsyncGenerator[dict, None]:
    """Scrape all events in a batch with parallel platform requests.

    Implements event-centric parallel scraping: for each event, all
    platforms are scraped concurrently, then results are stored before
    moving to the next event. Progress events are yielded throughout.

    Args:
        batch: ScrapeBatch with events to scrape and run metadata
        session: Async SQLAlchemy session for database operations

    Yields:
        Progress event dicts with type, platform, event_id, timing fields

    Note:
        Uses asyncio.Semaphore to limit intra-batch concurrency.
        Results go to async write queue if available, else sync commit.
    """
```

Do NOT change any functional code - only add/enhance docstrings.
  </action>
  <verify>python -m py_compile src/scraping/event_coordinator.py src/scraping/broadcaster.py src/scraping/clients/sportybet.py</verify>
  <done>All 12 scraping files have module docstrings, EventCoordinator fully documented, all client classes explain rate limiting and retries</done>
</task>

<task type="auto">
  <name>Task 2: Document support services</name>
  <files>src/caching/change_detection.py, src/caching/odds_cache.py, src/caching/warmup.py, src/scheduling/jobs.py, src/scheduling/scheduler.py, src/scheduling/stale_detection.py, src/matching/schemas.py, src/matching/service.py, src/services/cleanup.py, src/storage/write_handler.py, src/storage/write_queue.py</files>
  <action>
Add or enhance docstrings for all support service files:

1. **Caching layer**:
   - odds_cache.py: Document OddsCache class and frozen dataclass pattern
   - change_detection.py: Document normalized outcome comparison for detecting changes
   - warmup.py: Document warm_cache_from_db() startup pattern

2. **Scheduling layer**:
   - jobs.py: Document scrape_all_platforms job and APScheduler integration
   - scheduler.py: Document configure_scheduler, start/stop lifecycle
   - stale_detection.py: Document watchdog pattern for detecting stuck runs

3. **Matching layer**:
   - service.py: Document MatchingService and SportRadar ID matching
   - schemas.py: Document response schemas (MatchedEvent, InlineOdds, etc.)

4. **Storage layer**:
   - write_queue.py: Document AsyncWriteQueue bounded queue pattern
   - write_handler.py: Document batch processing with retry logic

5. **Services**:
   - cleanup.py: Document CleanupService retention and deletion logic

Format for classes:
```python
class OddsCache:
    """In-memory cache for latest odds snapshots per event/bookmaker.

    Replaces expensive GROUP BY queries with O(1) lookups. Uses frozen
    dataclasses (CachedSnapshot, CachedMarket) to avoid SQLAlchemy
    detached-instance issues.

    Thread-safe for single-writer/multi-reader asyncio usage (GIL
    protects dict mutations). Supports on_update callbacks for
    WebSocket broadcasting.

    Attributes:
        _betpawa_snapshots: Dict[event_id, Dict[bookmaker_id, CachedSnapshot]]
        _competitor_snapshots: Dict[event_id, Dict[slug, CachedSnapshot]]
        _event_kickoffs: Dict[event_id, datetime] for eviction
        _on_update_callbacks: List of sync callbacks fired on mutations
    """
```

Do NOT change any functional code - only add/enhance docstrings.
  </action>
  <verify>python -m py_compile src/caching/odds_cache.py src/scheduling/jobs.py src/storage/write_queue.py src/matching/service.py</verify>
  <done>All 11 support service files have module docstrings, all classes document their purpose and patterns, all functions have Args/Returns</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -m py_compile src/scraping/**/*.py src/caching/*.py src/scheduling/*.py src/storage/*.py` - All files compile
- [ ] Spot check: src/scraping/event_coordinator.py has EventCoordinator class docstring
- [ ] Spot check: src/caching/odds_cache.py has OddsCache class docstring with Attributes
- [ ] Spot check: src/storage/write_queue.py has AsyncWriteQueue documented
- [ ] Spot check: src/scheduling/jobs.py explains APScheduler integration
</verification>

<success_criteria>

- All 31 orchestration layer files have module-level docstrings
- All classes have docstrings documenting purpose, attributes, and patterns
- All async methods document concurrency considerations
- All functions have docstrings with Args/Returns/Raises
- No functional code changes - documentation only
- All files compile without errors
- Phase 76 complete
</success_criteria>

<output>
After completion, create `.planning/phases/76-documentation-backend/76-03-SUMMARY.md`
</output>
