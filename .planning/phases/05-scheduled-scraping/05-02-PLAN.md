---
phase: 05-scheduled-scraping
plan: 02
type: execute
---

<objective>
Create monitoring endpoints for scheduler status and run history visibility.

Purpose: Provide active monitoring so users can see what's happening at a glance - platform health and run history.
Output: GET /scheduler/status and GET /scheduler/history endpoints.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-scheduled-scraping/05-CONTEXT.md
@.planning/phases/05-scheduled-scraping/05-01-SUMMARY.md

# Key files:
@src/api/app.py
@src/scheduling/scheduler.py
@src/db/models/scrape.py
@src/api/routes/health.py

**Tech stack available:** FastAPI, SQLAlchemy async, APScheduler
**Established patterns:**
- APIRouter with prefix and tags
- Pydantic response models with ConfigDict
- Query params with ge=/le= validation
- get_db dependency for database session

**From context (essential requirements):**
- Monitoring shows both current platform health AND historical run data
- Visibility into what's happening at a glance
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create scheduler status endpoint</name>
  <files>src/api/routes/scheduler.py, src/api/schemas/scheduler.py</files>
  <action>
1. Create src/api/schemas/scheduler.py with Pydantic models:
   - JobStatus: id (str), next_run (datetime | None), trigger_type (str), interval_minutes (int | None)
   - SchedulerStatus: running (bool), jobs (list[JobStatus])
   - Use ConfigDict(from_attributes=True) for ORM compatibility pattern

2. Create src/api/routes/scheduler.py with:
   - router = APIRouter(prefix="/scheduler", tags=["scheduler"])
   - GET /status endpoint that:
     - Imports scheduler from src.scheduling.scheduler
     - Returns SchedulerStatus with running state and list of jobs
     - For each job: extract id, next_run_time, and interval from trigger if IntervalTrigger

Pattern for extracting interval:
```python
from apscheduler.triggers.interval import IntervalTrigger

for job in scheduler.get_jobs():
    interval_minutes = None
    if isinstance(job.trigger, IntervalTrigger):
        interval_minutes = int(job.trigger.interval.total_seconds() / 60)
    jobs.append(JobStatus(
        id=job.id,
        next_run=job.next_run_time,
        trigger_type=type(job.trigger).__name__,
        interval_minutes=interval_minutes,
    ))
```
  </action>
  <verify>python -c "from src.api.routes.scheduler import router; print('OK')"</verify>
  <done>GET /scheduler/status returns scheduler running state and job details with next run times</done>
</task>

<task type="auto">
  <name>Task 2: Create run history endpoint and wire router</name>
  <files>src/api/routes/scheduler.py, src/api/schemas/scheduler.py, src/api/app.py</files>
  <action>
1. Add to src/api/schemas/scheduler.py:
   - PlatformHealth: platform (str), healthy (bool), last_success (datetime | None)
   - RunHistoryEntry: id (int), status (str), started_at (datetime), completed_at (datetime | None), events_scraped (int), events_failed (int), trigger (str | None), duration_seconds (float | None)
   - RunHistoryResponse: runs (list[RunHistoryEntry]), total (int)

2. Add to src/api/routes/scheduler.py:
   - GET /history endpoint with query params:
     - limit: int = 20 (ge=1, le=100)
     - offset: int = 0 (ge=0)
     - status: str | None = None (filter by status)
   - Query ScrapeRun table ordered by started_at DESC
   - Calculate duration_seconds from completed_at - started_at if both exist
   - Return RunHistoryResponse with paginated results

   - GET /health endpoint (scheduler health, not platform health):
     - Returns platform health status using orchestrator.check_all_health()
     - Also include last successful scrape time per platform from ScrapeRun/ScrapeError join

3. Wire router in src/api/app.py:
   - Import: from api.routes.scheduler import router as scheduler_router
   - Add: app.include_router(scheduler_router)
  </action>
  <verify>python -c "from src.api.app import create_app; app = create_app(); routes = [r.path for r in app.routes]; assert '/scheduler/status' in routes; assert '/scheduler/history' in routes; print('OK')"</verify>
  <done>Run history endpoint returns paginated scrape runs, scheduler router wired to app</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] GET /scheduler/status returns scheduler state and job info
- [ ] GET /scheduler/history returns paginated run history
- [ ] Query parameters (limit, offset, status) work correctly
- [ ] All routes registered in app
</verification>

<success_criteria>
- Scheduler status endpoint shows running state and job details
- Run history endpoint shows recent scrape runs with filtering
- All verification checks pass
- Phase 5 complete
</success_criteria>

<output>
After completion, create `.planning/phases/05-scheduled-scraping/05-02-SUMMARY.md`
</output>
