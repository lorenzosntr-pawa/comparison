---
phase: 99-availability-tracking-fix
plan: 01-FIX
type: fix
---

<objective>
Fix 1 open UAT issue from plan 99-01.

Source: 99-01-ISSUES.md
Priority: 0 blocker (resolved during testing), 1 major

**Note:** UAT-001 (UnboundLocalError) was fixed during UAT session. This plan addresses UAT-002.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md

**Issues being fixed:**
@.planning/phases/99-availability-tracking-fix/99-01-ISSUES.md

**Original plan for reference:**
@.planning/phases/99-availability-tracking-fix/99-01-PLAN.md

**Key source files:**
@src/scraping/event_coordinator.py
@src/caching/availability_detection.py
@src/caching/odds_cache.py

**Root cause analysis (UAT-002):**

Current availability detection only runs for events that ARE scraped in a cycle:
1. `detect_availability_changes()` compares cache to new scrape data
2. This is called per-event inside the scraping loop
3. Events NOT in the scrape (not discovered or failed) are never checked
4. Old data stays marked "available" indefinitely

**Fix approach:**

After each scrape cycle, add a reconciliation pass:
1. Get all events in cache (for each platform)
2. Get events that were discovered in this cycle (per platform)
3. For events in cache but NOT in discovery for a platform:
   - That platform removed the event from their site
   - Mark ALL of that platform's markets as unavailable

This handles the case where a competitor (e.g., Bet9ja) no longer offers an event - their old odds should be marked unavailable.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Commit UAT-001 fix (already applied)</name>
  <files>src/scraping/event_coordinator.py</files>
  <action>
The fix for UAT-001 was already applied during UAT testing:
- Removed redundant local imports at lines 1688-1690 that shadowed module-level `update` import

Stage and commit this fix:
```bash
git add src/scraping/event_coordinator.py
git commit -m "fix(99-01): remove redundant local imports causing UnboundLocalError

UAT-001: Local import 'from sqlalchemy import update' at line 1688
shadowed module-level import, causing UnboundLocalError on first use
at line 1291 during scrape batch storage.

Fix: Removed three redundant local imports (sqlalchemy.update,
MarketOdds, CompetitorMarketOdds) - all already imported at module level.
"
```
  </action>
  <verify>git log -1 --oneline shows the commit</verify>
  <done>UAT-001 fix committed</done>
</task>

<task type="auto">
  <name>Task 2: Track discovered events per platform during discovery</name>
  <files>src/scraping/event_coordinator.py</files>
  <action>
During event discovery, we already track which events came from each platform. We need to expose this information for the reconciliation pass.

1. In the `discover_events()` method, the discovery results already contain platform information in the merged events. We need to track the SR IDs per platform.

2. Create a new dataclass to hold discovery tracking:
```python
@dataclass
class DiscoveryResult:
    """Track which events were discovered per platform."""
    betpawa_sr_ids: set[str]
    sportybet_sr_ids: set[str]
    bet9ja_sr_ids: set[str]
    merged_events: list[...]  # existing return type
```

3. Modify `discover_events()` to return this tracking info along with merged events:
   - After discovery, build sets of SR IDs per platform
   - Return DiscoveryResult instead of just the merged list

4. Update callers to use the new return type.

**Note:** The discovery already fetches events from each platform separately (betpawa_events, sportybet_events, bet9ja_events). We just need to extract and return the SR ID sets.
  </action>
  <verify>python -c "from src.scraping.event_coordinator import DiscoveryResult; print('DiscoveryResult exists')"</verify>
  <done>Discovery tracks SR IDs per platform</done>
</task>

<task type="auto">
  <name>Task 3: Add cache reconciliation for missing events</name>
  <files>src/scraping/event_coordinator.py, src/caching/odds_cache.py</files>
  <action>
1. Add method to OddsCache to get all cached event IDs per bookmaker:
```python
def get_cached_events_by_bookmaker(self) -> dict[str, set[int]]:
    """Return event IDs in cache grouped by bookmaker slug.

    Returns:
        Dict mapping bookmaker_slug -> set of betpawa_event_ids
    """
    result = {"betpawa": set(), "sportybet": set(), "bet9ja": set()}

    # BetPawa events - all events in _betpawa_snapshots
    result["betpawa"] = set(self._betpawa_snapshots.keys())

    # Competitor events - from _competitor_snapshots
    for event_id, sources in self._competitor_snapshots.items():
        for source in sources.keys():
            if source == "sportybet":
                result["sportybet"].add(event_id)
            elif source == "bet9ja":
                result["bet9ja"].add(event_id)

    return result
```

2. Add method to OddsCache to get SR ID for an event:
```python
def get_sr_id_for_event(self, event_id: int) -> str | None:
    """Get sportradar_id for a cached event."""
    snap = self._betpawa_snapshots.get(event_id)
    if snap:
        return snap.sportradar_id
    return None
```

3. In EventCoordinator, add reconciliation method:
```python
async def _reconcile_unavailable_events(
    self,
    discovery: DiscoveryResult,
    timestamp: datetime,
    db: AsyncSession,
) -> int:
    """Mark markets unavailable for events dropped from discovery.

    For each platform, find events that:
    - Exist in cache (were previously scraped)
    - Were NOT in this cycle's discovery (platform no longer offers them)

    Mark all markets for that platform+event as unavailable.

    Returns:
        Count of markets marked unavailable
    """
    if self._odds_cache is None:
        return 0

    from sqlalchemy import update
    from src.db.models.odds import MarketOdds
    from src.db.models.competitor import CompetitorMarketOdds

    cached_events = self._odds_cache.get_cached_events_by_bookmaker()
    unavailable_count = 0

    # Check BetPawa events
    for event_id in cached_events["betpawa"]:
        sr_id = self._odds_cache.get_sr_id_for_event(event_id)
        if sr_id and sr_id not in discovery.betpawa_sr_ids:
            # BetPawa no longer has this event - mark all BetPawa markets unavailable
            snap = self._odds_cache.get_betpawa_snapshot(event_id)
            if snap and snap.snapshot_id:
                result = await db.execute(
                    update(MarketOdds)
                    .where(
                        MarketOdds.snapshot_id == snap.snapshot_id,
                        MarketOdds.unavailable_at.is_(None)
                    )
                    .values(unavailable_at=timestamp)
                )
                unavailable_count += result.rowcount

    # Check competitor events (SportyBet, Bet9ja)
    for event_id in cached_events["sportybet"]:
        sr_id = self._odds_cache.get_sr_id_for_event(event_id)
        if sr_id and sr_id not in discovery.sportybet_sr_ids:
            # SportyBet no longer has this event
            existing = self._odds_cache.get_competitor_snapshot(event_id)
            if existing and "sportybet" in existing:
                snap = existing["sportybet"]
                if snap.snapshot_id:
                    result = await db.execute(
                        update(CompetitorMarketOdds)
                        .where(
                            CompetitorMarketOdds.snapshot_id == snap.snapshot_id,
                            CompetitorMarketOdds.unavailable_at.is_(None)
                        )
                        .values(unavailable_at=timestamp)
                    )
                    unavailable_count += result.rowcount

    for event_id in cached_events["bet9ja"]:
        sr_id = self._odds_cache.get_sr_id_for_event(event_id)
        if sr_id and sr_id not in discovery.bet9ja_sr_ids:
            # Bet9ja no longer has this event
            existing = self._odds_cache.get_competitor_snapshot(event_id)
            if existing and "bet9ja" in existing:
                snap = existing["bet9ja"]
                if snap.snapshot_id:
                    result = await db.execute(
                        update(CompetitorMarketOdds)
                        .where(
                            CompetitorMarketOdds.snapshot_id == snap.snapshot_id,
                            CompetitorMarketOdds.unavailable_at.is_(None)
                        )
                        .values(unavailable_at=timestamp)
                    )
                    unavailable_count += result.rowcount

    if unavailable_count > 0:
        await db.commit()
        logger.info(
            "reconciliation.unavailable_events",
            markets_marked_unavailable=unavailable_count,
        )

    return unavailable_count
```

4. Call reconciliation at the end of run_full_cycle(), after all batches processed:
```python
# After all batches complete, reconcile events dropped from discovery
unavailable_count = await self._reconcile_unavailable_events(
    discovery=discovery_result,
    timestamp=datetime.now(timezone.utc).replace(tzinfo=None),
    db=db,
)
if unavailable_count > 0:
    logger.info(
        "scrape_cycle.reconciliation_complete",
        markets_marked_unavailable=unavailable_count,
    )
```
  </action>
  <verify>Trigger a scrape and check logs for "reconciliation.unavailable_events" message. Check that stale competitor data now shows unavailable_at != NULL in database.</verify>
  <done>Events dropped from discovery have their markets marked unavailable</done>
</task>

<task type="auto">
  <name>Task 4: Update cache to reflect unavailable status</name>
  <files>src/caching/odds_cache.py</files>
  <action>
After marking markets unavailable in the database, we also need to update the in-memory cache so the API immediately reflects the change.

1. Add method to OddsCache to mark a snapshot's markets as unavailable:
```python
def mark_snapshot_unavailable(
    self,
    event_id: int,
    bookmaker_slug: str,
    timestamp: datetime,
) -> int:
    """Mark all markets in a snapshot as unavailable.

    Returns count of markets marked.
    """
    count = 0

    if bookmaker_slug == "betpawa":
        snap = self._betpawa_snapshots.get(event_id)
        if snap:
            # Create updated markets with unavailable_at set
            updated_markets = tuple(
                replace(m, unavailable_at=timestamp) if m.unavailable_at is None else m
                for m in snap.markets
            )
            count = sum(1 for m in updated_markets if m.unavailable_at == timestamp)
            # Update the snapshot
            self._betpawa_snapshots[event_id] = replace(snap, markets=updated_markets)
    else:
        existing = self._competitor_snapshots.get(event_id)
        if existing and bookmaker_slug in existing:
            snap = existing[bookmaker_slug]
            updated_markets = tuple(
                replace(m, unavailable_at=timestamp) if m.unavailable_at is None else m
                for m in snap.markets
            )
            count = sum(1 for m in updated_markets if m.unavailable_at == timestamp)
            existing[bookmaker_slug] = replace(snap, markets=updated_markets)

    return count
```

2. In reconciliation method, after DB update, also update cache:
```python
# After DB update for each platform/event:
if self._odds_cache:
    self._odds_cache.mark_snapshot_unavailable(
        event_id=event_id,
        bookmaker_slug="bet9ja",  # or appropriate slug
        timestamp=timestamp,
    )
```
  </action>
  <verify>After scrape, check API response for a stale event - should show available=false for the stale bookmaker</verify>
  <done>Cache updated alongside database for immediate API effect</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] UAT-001 fix committed
- [ ] DiscoveryResult dataclass exists and tracks SR IDs per platform
- [ ] Reconciliation runs after each scrape cycle
- [ ] Events dropped from discovery have markets marked unavailable
- [ ] Cache reflects unavailable status immediately
- [ ] All existing tests pass
- [ ] Manual test: stale competitor data now shows as unavailable in UI
</verification>

<success_criteria>
- UAT-001 fix committed
- UAT-002 fixed: Events not in discovery have their markets marked unavailable
- Cache and DB both updated
- API correctly returns available=false for stale data
- Ready for re-verification
</success_criteria>

<output>
After completion, create `.planning/phases/99-availability-tracking-fix/99-01-FIX-SUMMARY.md`
</output>
