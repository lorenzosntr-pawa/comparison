# Phase 6.1: Cross-Platform Scraping - Research

**Researched:** 2026-01-21
**Domain:** Multi-platform betting odds scraping with SportRadar ID matching
**Confidence:** HIGH

<research_summary>
## Summary

This phase completes the scraping orchestrator to fetch events and odds from SportyBet and Bet9ja, matching them to existing BetPawa events via SportRadar IDs. All infrastructure exists - the clients work, the database schema is ready, and the EventMatchingService handles upserts.

**Key finding:** All three platforms use SportRadar IDs (though formatted differently):
- BetPawa: `widgets[type=SPORTRADAR].id` → e.g., `"65905654"` (numeric string)
- SportyBet: `eventId` parameter → e.g., `"sr:match:61300947"` (prefixed format)
- Bet9ja: `EXTID` field → e.g., `"65905654"` (numeric string matching BetPawa)

**Primary recommendation:** Implement BetPawa-first sequential scraping. BetPawa discovers events, then query DB for SportRadar IDs to fetch from competitors. Store raw API responses for full flexibility.
</research_summary>

<standard_stack>
## Standard Stack

### Core (Already Implemented)
| Library | Version | Purpose | Status |
|---------|---------|---------|--------|
| httpx | 0.27+ | Async HTTP client | ✅ Working clients |
| tenacity | 8.2+ | Retry logic | ✅ _retry decorator |
| SQLAlchemy | 2.0+ | Async ORM | ✅ Event models |
| APScheduler | 3.10+ | Background jobs | ✅ Scheduler |

### Existing Components
| Component | Location | Purpose |
|-----------|----------|---------|
| BetPawaClient | `src/scraping/clients/betpawa.py` | fetch_event, fetch_events, fetch_categories |
| SportyBetClient | `src/scraping/clients/sportybet.py` | fetch_event(sportradar_id) |
| Bet9jaClient | `src/scraping/clients/bet9ja.py` | fetch_event, fetch_events(tournament_id), fetch_sports |
| EventMatchingService | `src/matching/service.py` | upsert_tournament, upsert_event, upsert_event_bookmaker |
| ScrapingOrchestrator | `src/scraping/orchestrator.py` | Needs completion for SportyBet/Bet9ja |
| OddsSnapshot | `src/db/models/odds.py` | raw_response JSONB column ready |

### No New Dependencies Needed
The existing stack handles everything required. No external libraries needed.
</standard_stack>

<architecture_patterns>
## Architecture Patterns

### Recommended Scraping Flow
```
1. BetPawa Scrape (existing - works)
   └─> Discover competitions via fetch_categories("2")
   └─> Fetch events per competition
   └─> Parse SportRadar ID from widgets[type=SPORTRADAR].id
   └─> Upsert events + create bookmaker_links

2. SportyBet Scrape (NEW)
   └─> Query DB for events with sportradar_id
   └─> For each: fetch_event(f"sr:match:{sportradar_id}")
   └─> Parse odds from response
   └─> Store raw_response in OddsSnapshot
   └─> Create/update bookmaker_link

3. Bet9ja Scrape (NEW)
   └─> Fetch all football tournaments via fetch_sports()
   └─> For each tournament: fetch_events(tournament_id)
   └─> Extract EXTID (SportRadar ID) from each event
   └─> Match to existing events by sportradar_id
   └─> Store raw_response + create bookmaker_link
   └─> Flag unmatched events (competitor-only)
```

### SportRadar ID Format Conversion
```python
# BetPawa/Bet9ja → SportyBet
def to_sportybet_id(numeric_id: str) -> str:
    """Convert numeric SportRadar ID to SportyBet format."""
    return f"sr:match:{numeric_id}"

# SportyBet → BetPawa/Bet9ja (for reverse lookup if needed)
def to_numeric_id(sportybet_id: str) -> str:
    """Extract numeric ID from sr:match:NNNNN format."""
    return sportybet_id.replace("sr:match:", "")
```

### Database Query Pattern for Competitor Scraping
```python
# Get events needing competitor data
async def get_events_for_competitor_scrape(
    db: AsyncSession,
    platform: Platform,
    bookmaker_id: int,
) -> list[Event]:
    """Get events that need scraping for a competitor platform.

    Returns events that:
    1. Have a SportRadar ID
    2. Haven't started yet (kickoff > now)
    3. Either:
       a. Don't have a bookmaker_link for this platform (new match)
       b. Have a link but need fresh odds (existing match)
    """
    now = datetime.utcnow()

    # All events with sportradar_id that haven't started
    stmt = (
        select(Event)
        .where(
            Event.sportradar_id.isnot(None),
            Event.kickoff > now,
        )
    )
    result = await db.execute(stmt)
    return result.scalars().all()
```

### Anti-Patterns to Avoid
- **Parallel competitor scraping without rate limiting:** Bet9ja and SportyBet may rate-limit. Use sequential with delays.
- **Fetching event details when listing has odds:** For Bet9ja, tournament listing includes basic odds - can optimize later.
- **Not handling missing events:** Some BetPawa events won't exist on competitors - log and continue.
</architecture_patterns>

<dont_hand_roll>
## Don't Hand-Roll

| Problem | Existing Solution | Location |
|---------|-------------------|----------|
| Event upsert logic | EventMatchingService.upsert_event | `src/matching/service.py` |
| Tournament upsert | EventMatchingService.upsert_tournament | `src/matching/service.py` |
| Bookmaker link creation | EventMatchingService.upsert_event_bookmaker | `src/matching/service.py` |
| Retry with backoff | `create_retry_decorator()` | `src/scraping/clients/base.py` |
| Error logging to DB | `_log_error()` | `src/scraping/orchestrator.py` |
| Bookmaker ID lookup | `_get_bookmaker_id()` | `src/scraping/orchestrator.py` |

**Key insight:** The EventMatchingService already implements Betpawa-first priority semantics. Competitors only update kickoff time, not metadata. Use existing patterns.
</dont_hand_roll>

<common_pitfalls>
## Common Pitfalls

### Pitfall 1: SportRadar ID Format Mismatch
**What goes wrong:** SportyBet returns 404 for numeric ID, needs "sr:match:" prefix
**Why it happens:** BetPawa/Bet9ja use numeric IDs, SportyBet uses prefixed format
**How to avoid:** Always convert: `f"sr:match:{betpawa_sportradar_id}"`
**Warning signs:** All SportyBet fetches failing with InvalidEventIdError

### Pitfall 2: Bet9ja EXTID is Nullable
**What goes wrong:** Event has no EXTID, can't match
**Why it happens:** Not all Bet9ja events have SportRadar IDs (older/minor events)
**How to avoid:** Skip events without EXTID, log for tracking
**Warning signs:** NoneType errors when accessing EXTID

### Pitfall 3: Started Events Return Different Data
**What goes wrong:** Event returns live/in-play data instead of prematch
**Why it happens:** Event started between scrape initiation and fetch
**How to avoid:** Check kickoff time before fetch, skip if past; handle API status field
**Warning signs:** Odds suddenly very different, status fields showing LIVE

### Pitfall 4: Tournament ID Discovery for Bet9ja
**What goes wrong:** Can't fetch events without knowing tournament IDs
**Why it happens:** Bet9ja API requires tournament ID, not competition name
**How to avoid:** Use fetch_sports() to get full navigation → extract football tournaments
**Warning signs:** Empty results when trying to fetch Bet9ja events

### Pitfall 5: Rate Limiting
**What goes wrong:** API returns 429 or blocks
**Why it happens:** Too many concurrent requests
**How to avoid:** Sequential fetching with small delays (0.1-0.5s between requests)
**Warning signs:** Sporadic failures, increasing error counts
</common_pitfalls>

<code_examples>
## Code Examples

### SportyBet Scraping Pattern
```python
async def _scrape_sportybet(
    self,
    client: SportyBetClient,
    db: AsyncSession,
) -> list[dict]:
    """Scrape SportyBet events by SportRadar ID lookup."""
    events = []

    # Get events from DB that need SportyBet data
    now = datetime.utcnow()
    result = await db.execute(
        select(Event)
        .where(Event.sportradar_id.isnot(None))
        .where(Event.kickoff > now)
    )
    db_events = result.scalars().all()

    for event in db_events:
        sportybet_id = f"sr:match:{event.sportradar_id}"
        try:
            data = await client.fetch_event(sportybet_id)
            events.append({
                "sportradar_id": event.sportradar_id,
                "external_event_id": sportybet_id,
                "event_url": f"https://www.sportybet.com/ng/sport/football/event/{sportybet_id}",
                "raw_data": data,  # Store full API response
                "db_event": event,  # Reference for bookmaker_link
            })
        except InvalidEventIdError:
            # Event doesn't exist on SportyBet - log and continue
            logger.debug(f"Event {sportybet_id} not found on SportyBet")
        except Exception as e:
            logger.warning(f"Failed to fetch {sportybet_id}: {e}")

        await asyncio.sleep(0.1)  # Rate limiting

    return events
```

### Bet9ja Scraping Pattern
```python
async def _scrape_bet9ja(
    self,
    client: Bet9jaClient,
) -> list[dict]:
    """Scrape Bet9ja events via tournament discovery."""
    events = []

    # Get all football tournaments
    sports_data = await client.fetch_sports()
    tournaments = _extract_football_tournaments(sports_data)

    for tournament_id in tournaments:
        try:
            tournament_events = await client.fetch_events(tournament_id)
            for event_data in tournament_events:
                extid = event_data.get("EXTID")
                if not extid:
                    continue  # Skip events without SportRadar ID

                events.append({
                    "sportradar_id": extid,
                    "external_event_id": str(event_data.get("C")),  # Bet9ja code
                    "event_url": f"https://sports.bet9ja.com/event/{event_data.get('C')}",
                    "raw_data": event_data,
                    "home_team": event_data.get("DS", "").split(" - ")[0],
                    "away_team": event_data.get("DS", "").split(" - ")[-1],
                    "kickoff": datetime.strptime(
                        event_data.get("STARTDATE"),
                        "%Y-%m-%d %H:%M:%S"
                    ),
                })
        except Exception as e:
            logger.warning(f"Failed to scrape tournament {tournament_id}: {e}")

        await asyncio.sleep(0.2)  # Rate limiting

    return events

def _extract_football_tournaments(sports_data: dict) -> list[str]:
    """Extract football tournament IDs from GetSports response."""
    tournament_ids = []
    pal = sports_data.get("D", {}).get("PAL", {})

    # Football sport ID in Bet9ja
    football = pal.get("1", {})  # Sport ID 1 = Soccer
    sport_groups = football.get("SG", {})

    for sg_id, sg_data in sport_groups.items():
        groups = sg_data.get("G", {})
        for g_id in groups.keys():
            tournament_ids.append(g_id)

    return tournament_ids
```

### Storing Raw Response as OddsSnapshot
```python
async def _store_odds_snapshot(
    self,
    db: AsyncSession,
    event_id: int,
    bookmaker_id: int,
    raw_data: dict,
    scrape_run_id: int | None = None,
) -> OddsSnapshot:
    """Store raw API response as odds snapshot."""
    snapshot = OddsSnapshot(
        event_id=event_id,
        bookmaker_id=bookmaker_id,
        raw_response=raw_data,
        scrape_run_id=scrape_run_id,
    )
    db.add(snapshot)
    await db.flush()
    return snapshot
```
</code_examples>

<api_specifics>
## API Response Structures

### BetPawa Event Response (widgets contain SportRadar ID)
```json
{
    "id": "32299257",
    "name": "Brighton & Hove Albion - AFC Bournemouth",
    "widgets": [
        {"id": "65905654", "type": "SPORTRADAR", "retention": "PREMATCH"}
    ],
    "participants": [
        {"id": "656120", "name": "Brighton & Hove Albion", "position": 1},
        {"id": "656697", "name": "AFC Bournemouth", "position": 2}
    ],
    "startTime": "2026-01-19T20:00:00Z",
    "markets": [...]
}
```

### SportyBet Event Response (full match data)
```
URL: /api/ng/factsCenter/event?eventId=sr:match:61300947&productId=3
Response: { "bizCode": 10000, "data": { ... full event data with odds ... } }
```

### Bet9ja Tournament Events Response (events include EXTID)
```json
{
    "R": "OK",
    "D": {
        "E": [
            {
                "C": "1680",
                "EXTID": "65905654",
                "DS": "Brighton - Bournemouth",
                "STARTDATE": "2026-01-19 20:00:00",
                "SID": 1,
                "O": { ... odds data ... }
            }
        ]
    }
}
```

### Key Field Mappings
| Platform | Event ID | SportRadar ID | Home/Away | Kickoff |
|----------|----------|---------------|-----------|---------|
| BetPawa | `id` | `widgets[SPORTRADAR].id` | `participants[1,2].name` | `startTime` (ISO) |
| SportyBet | `eventId` (with prefix) | URL param | Response data | Response data |
| Bet9ja | `C` (code) | `EXTID` | `DS` (split by " - ") | `STARTDATE` |
</api_specifics>

<open_questions>
## Open Questions

1. **SportyBet rate limits**
   - What we know: No explicit rate limit documented, but large batches may trigger blocks
   - What's unclear: Exact threshold for rate limiting
   - Recommendation: Start with 0.1s delay, increase if 429s occur

2. **Bet9ja tournament completeness**
   - What we know: fetch_sports returns full PAL structure
   - What's unclear: Are all tournaments included, or are some filtered?
   - Recommendation: Scrape everything returned, compare coverage to BetPawa over time

3. **Event lifecycle handling**
   - What we know: Started events should be archived
   - What's unclear: Best strategy for detecting started state across platforms
   - Recommendation: Use kickoff time as primary signal, API status as confirmation
</open_questions>

<sources>
## Sources

### Primary (HIGH confidence)
- `scraper/responses_examples/betpawa/event/event_response.json` - BetPawa API structure
- `scraper/responses_examples/sportybet/event_header.txt` - SportyBet request format
- `scraper/responses_examples/bet9ja/tournament/tournament_response.json` - Bet9ja EXTID field

### Secondary (HIGH confidence - existing codebase)
- `src/scraping/clients/sportybet.py` - Working SportyBet client
- `src/scraping/clients/bet9ja.py` - Working Bet9ja client
- `src/matching/service.py` - EventMatchingService patterns
- `src/db/models/odds.py` - OddsSnapshot with raw_response column
</sources>

<metadata>
## Metadata

**Research scope:**
- Core technology: Multi-platform API scraping
- Ecosystem: Existing httpx clients, SQLAlchemy models
- Patterns: BetPawa-first scraping, SportRadar ID matching
- Pitfalls: ID format conversion, rate limiting, missing events

**Confidence breakdown:**
- API structures: HIGH - verified with actual response examples
- ID matching: HIGH - confirmed all platforms use SportRadar IDs
- Architecture: HIGH - builds on existing working patterns
- Code examples: HIGH - based on existing client implementations

**Research date:** 2026-01-21
**Valid until:** 2026-02-21 (30 days - API structures unlikely to change)
</metadata>

---

*Phase: 06.1-cross-platform-scraping*
*Research completed: 2026-01-21*
*Ready for planning: yes*
