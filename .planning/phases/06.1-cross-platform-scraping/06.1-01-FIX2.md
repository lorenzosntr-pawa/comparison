---
phase: 06.1-cross-platform-scraping
plan: 06.1-01-FIX2
type: fix
---

<objective>
Fix 2 UAT issues from plan 06.1-01 (second fix round).

Source: 06.1-01-ISSUES.md
Priority: 1 blocker, 1 major

**Issues addressed:**
- UAT-005 (Blocker): Missing sports seed data - Football (id=1) doesn't exist
- UAT-004 (Major): Database transaction error when logging scrape errors
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md

**Issues being fixed:**
@.planning/phases/06.1-cross-platform-scraping/06.1-01-ISSUES.md

**Relevant files:**
@alembic/versions/845263fcf673_initial_schema.py
@src/db/models/sport.py
@src/scraping/orchestrator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add sports seed data migration</name>
  <files>alembic/versions/[new]_seed_sports_data.py</files>
  <action>
Create a new Alembic migration to seed the sports table with reference data.

1. Generate migration: `alembic revision -m "seed_sports_data"`
2. Add INSERT statement for Football:
   ```python
   op.execute("""
       INSERT INTO sports (id, name, slug) VALUES
       (1, 'Football', 'football')
       ON CONFLICT (id) DO NOTHING
   """)
   ```
3. downgrade() should DELETE WHERE id = 1

**Note:** Use explicit id=1 since our code hardcodes sport_id=1 for football.
The ON CONFLICT handles re-runs.
  </action>
  <verify>
Run: `alembic upgrade head`
Then query: SELECT * FROM sports;
Should show Football with id=1
  </verify>
  <done>Sports table has Football (id=1, name='Football', slug='football')</done>
</task>

<task type="auto">
  <name>Task 2: Fix transaction rollback in orchestrator error handling</name>
  <files>src/scraping/orchestrator.py</files>
  <action>
Fix the `InFailedSQLTransactionError` by adding rollback before error logging.

In `scrape_all()` method, around line 114-122, when catching exceptions during `_store_events()`:

1. Add `await db.rollback()` BEFORE calling `_log_error()`
2. This clears the failed transaction state so subsequent queries work

Current code (lines ~114-122):
```python
except Exception as e:
    logger.exception(
        f"Failed to store events for {platform}: {e}"
    )
    if scrape_run_id:
        await self._log_error(
            db, scrape_run_id, platform, e
        )
```

Changed code:
```python
except Exception as e:
    logger.exception(
        f"Failed to store events for {platform}: {e}"
    )
    if scrape_run_id and db:
        await db.rollback()  # Clear failed transaction state
        await self._log_error(
            db, scrape_run_id, platform, e
        )
```

Also check if there are other places that call _log_error() after a potential failure and add rollback there too (around line 96 where platform failures are caught).
  </action>
  <verify>
1. Trigger a scrape that will fail storage: `POST /scrape` with fresh database
2. Should NOT get 500 Internal Server Error
3. Should get proper partial/failed response with error logged
  </verify>
  <done>Scrape errors are logged without triggering InFailedSQLTransactionError</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Migration created and runs without error
- [ ] Sports table has Football (id=1)
- [ ] BetPawa scrape completes without FK violation
- [ ] Scrape errors are logged without transaction errors
- [ ] Server doesn't crash on scrape failures
</verification>

<success_criteria>
- UAT-005 resolved: Sports table seeded with Football
- UAT-004 resolved: Transaction rollback before error logging
- BetPawa scraping can store events successfully
- Error handling is robust (no 500 errors on storage failures)
</success_criteria>

<output>
After completion, create `.planning/phases/06.1-cross-platform-scraping/06.1-01-FIX2-SUMMARY.md`
</output>
