---
phase: 32-connection-loss-logging
plan: "01"
type: execute
---

<objective>
Detect SSE connection loss during manual scrapes, mark runs with a distinct `connection_failed` status, log the event, and auto-trigger a rescrape when the frontend recovers.

Purpose: Make connection failures visible and recoverable instead of leaving runs stuck as "running."
Output: Backend disconnect detection, new CONNECTION_FAILED status in DB + UI, auto-rescrape on page reload.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/32-connection-loss-logging/32-RESEARCH.md
@.planning/phases/32-connection-loss-logging/32-CONTEXT.md
@.planning/phases/31-backend-heartbeat/31-01-SUMMARY.md

# Key source files:
@src/db/models/scrape.py
@src/api/routes/scrape.py
@src/scraping/broadcaster.py
@src/scheduling/stale_detection.py
@web/src/features/scrape-runs/hooks/use-scrape-progress.ts
@web/src/features/dashboard/hooks/use-observe-scrape.ts
@web/src/features/dashboard/components/recent-runs.tsx
@web/src/features/scrape-runs/components/runs-table.tsx
@web/src/features/scrape-runs/detail.tsx

**Tech stack:** Python (FastAPI, SQLAlchemy 2.0 async, structlog), React (TanStack Query v5), SSE via Starlette StreamingResponse
**Established patterns:** ScrapeStatus StrEnum stored as VARCHAR(20), ProgressBroadcaster pub/sub, fire-and-forget background tasks, statusVariants mapping in frontend Badge components
**Constraining decisions:**
- Phase 31: Stale detection watches RUNNING runs — must recognize CONNECTION_FAILED as terminal
- Status stored as String(20) VARCHAR — no Alembic migration needed for new enum value
- Background task runs independently of SSE connection (asyncio.create_task fire-and-forget)

**Issues being addressed:** None from ISSUES.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add CONNECTION_FAILED status and backend disconnect detection</name>
  <files>src/db/models/scrape.py, src/scraping/broadcaster.py, src/api/routes/scrape.py, src/scheduling/stale_detection.py</files>
  <action>
1. **Add enum value** in `src/db/models/scrape.py`: Add `CONNECTION_FAILED = "connection_failed"` to `ScrapeStatus` enum after FAILED. No migration needed — stored as VARCHAR.

2. **Add subscriber_count property** to `ProgressBroadcaster` in `src/scraping/broadcaster.py`:
   ```python
   @property
   def subscriber_count(self) -> int:
       return len(self._subscribers)
   ```

3. **Add disconnect detection** in `run_scrape_background()` in `src/api/routes/scrape.py`:
   - After each `await broadcaster.publish(progress)` call inside the `async for` loop, check if this is a platform-level completion event (`progress.platform and progress.phase == "completed"` or `progress.phase == "failed"`).
   - When a platform completes, check `broadcaster.subscriber_count == 0`. If zero subscribers AND the scrape hasn't finished all platforms yet (not the final overall completion event), set `final_status = ScrapeStatus.CONNECTION_FAILED` and break out of the progress loop.
   - Log with structlog: `logger.warning("sse_client_disconnected", scrape_run_id=scrape_run_id, last_platform=progress.platform.value)`.
   - Import structlog at top of file if not already: `import structlog; logger = structlog.get_logger()`.
   - **Critical race condition guard:** Only check subscriber count BETWEEN platforms (after a platform completion event), never after the final overall completion event. If the final `progress.platform is None and progress.phase in ("completed", "failed")` event arrives, let the normal status logic handle it — the scrape succeeded regardless of subscribers.
   - **Only apply to trigger="api-stream"** — the ScrapeRun already has trigger="api-stream" for manual scrapes. Scheduled scrapes use a different code path and don't go through this function.

4. **Update stale detection** in `src/scheduling/stale_detection.py`:
   - In `find_stale_runs()`, the WHERE clause already filters for `ScrapeStatus.RUNNING` only, so CONNECTION_FAILED runs are automatically excluded. No change needed there.
   - However, in `recover_stale_runs_on_startup()`, the query also filters for RUNNING only — so also fine. No changes needed to stale detection.
  </action>
  <verify>
- `python -c "from src.db.models.scrape import ScrapeStatus; print(ScrapeStatus.CONNECTION_FAILED)"` prints `connection_failed`
- `python -c "from src.scraping.broadcaster import ProgressBroadcaster; b = ProgressBroadcaster(1); print(b.subscriber_count)"` prints `0`
- Grep for `CONNECTION_FAILED` in scrape.py routes confirms disconnect detection logic exists
  </verify>
  <done>CONNECTION_FAILED enum value exists, broadcaster exposes subscriber_count, background task detects zero subscribers between platforms and sets connection_failed status with structlog warning</done>
</task>

<task type="auto">
  <name>Task 2: Frontend disconnect handling, status display, and auto-rescrape</name>
  <files>web/src/features/dashboard/components/recent-runs.tsx, web/src/features/scrape-runs/components/runs-table.tsx, web/src/features/scrape-runs/detail.tsx, web/src/features/scrape-runs/hooks/use-scrape-progress.ts, web/src/features/dashboard/hooks/use-observe-scrape.ts, web/src/features/dashboard/components/scrape-control.tsx</files>
  <action>
1. **Add connection_failed to statusVariants** in all three UI files that define the mapping (`recent-runs.tsx`, `runs-table.tsx`, `detail.tsx`):
   ```typescript
   const statusVariants: Record<string, ...> = {
     completed: 'default',
     partial: 'secondary',
     failed: 'destructive',
     connection_failed: 'destructive',  // Same red as failed
     running: 'outline',
     pending: 'outline',
   }
   ```
   Also update any status label display to show "Connection Failed" for `connection_failed` status. Find where status text is rendered (likely `run.status` displayed directly) and add a formatting helper or inline conditional:
   ```typescript
   const formatStatus = (status: string) =>
     status === 'connection_failed' ? 'Connection Lost' : status.charAt(0).toUpperCase() + status.slice(1)
   ```

2. **Handle connection_failed in completion check** in `use-scrape-progress.ts`:
   - In the `onmessage` handler (line ~149), the completion check is `data.phase === 'completed' || data.phase === 'failed'`. The backend won't send a `connection_failed` phase event via SSE (the SSE is already dead when this happens), so no change needed to the SSE message handler.
   - In `use-observe-scrape.ts`, same situation — no SSE event for connection_failed.

3. **Auto-rescrape on recovery**: In the dashboard's scrape control component (find where the "Scrape Now" button lives — likely `scrape-control.tsx` or similar), add logic that checks on mount/reload if the latest run has status `connection_failed`:
   - Use the existing `/api/scrape/runs` endpoint (already fetched by the dashboard) to check the most recent run's status.
   - If the latest run is `connection_failed`, auto-trigger a new scrape by calling the existing scrape start mechanism (the same handler the "Scrape Now" button uses).
   - Add a structlog-style console.log: `console.info('Auto-rescraping after connection failure', { lastRunId })`.
   - Guard against infinite loops: only auto-trigger once per page load using a `useRef<boolean>` flag.
   - This should be subtle — no modal or dialog, just auto-start and show the normal progress UI.
  </action>
  <verify>
- Search frontend for `connection_failed` — should appear in statusVariants in 3 files
- Search for `Connection Lost` — should appear in status label formatting
- Search for auto-rescrape logic — should find the useRef guard and auto-trigger
- `cd web && npx tsc --noEmit` passes with no type errors
  </verify>
  <done>connection_failed status renders with red destructive badge and "Connection Lost" label in all run list views. Auto-rescrape triggers on page load when latest run is connection_failed. TypeScript compiles clean.</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `python -c "from src.db.models.scrape import ScrapeStatus; assert ScrapeStatus.CONNECTION_FAILED == 'connection_failed'"` passes
- [ ] `cd web && npx tsc --noEmit` passes (no TypeScript errors)
- [ ] Grep confirms CONNECTION_FAILED in backend route disconnect detection
- [ ] Grep confirms connection_failed in frontend statusVariants (3 files)
- [ ] Grep confirms auto-rescrape logic with loop guard
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- CONNECTION_FAILED is a distinct status from FAILED
- Backend detects zero SSE subscribers between platforms and marks run accordingly
- Frontend displays connection_failed with appropriate badge styling
- Auto-rescrape triggers once on page reload when latest run is connection_failed
- No TypeScript or Python import errors
  </success_criteria>

<output>
After completion, create `.planning/phases/32-connection-loss-logging/32-01-SUMMARY.md`
</output>
