---
phase: 88-backend-availability-tracking
plan: 01
type: execute
---

<objective>
Implement availability tracking infrastructure: schema changes, cache dataclass updates, and detection logic integrated into scraping pipeline.

Purpose: Enable the system to track when markets become unavailable (disappeared from bookmaker) vs never offered, providing foundation for UI display and history visualization.
Output: Working backend pipeline that detects market availability changes and persists them to database.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/87-investigation-schema-design/DISCOVERY.md
@.planning/phases/87-investigation-schema-design/87-01-SUMMARY.md

# Key source files:
@src/db/models/odds.py
@src/db/models/competitor.py
@src/caching/odds_cache.py
@src/caching/change_detection.py
@src/scraping/event_coordinator.py

**Design from Phase 87:**
- Option B selected: `unavailable_at` nullable timestamp column
- Detection at cache layer: compare previous cache state to new scrape results
- Semantics: NULL = available, timestamp = unavailable since that time

**Tech stack available:**
- SQLAlchemy 2.0 async with Alembic migrations
- Frozen dataclasses for cache entries (CachedMarket, CachedSnapshot)
- structlog for logging

**Established patterns:**
- Change detection via normalized outcome comparison (change_detection.py)
- get_market_key(market_id, line) for unique market identification
- Cache-before-persist: update cache immediately, persist asynchronously

**Constraining decisions:**
- Phase 87: unavailable_at timestamp (not boolean, not separate table)
- Phase 87: Detection by comparing market keys (previous cache vs new scrape)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Schema Migration + ORM Model Updates</name>
  <files>alembic/versions/xxxx_add_unavailable_at.py, src/db/models/odds.py, src/db/models/competitor.py</files>
  <action>
Create Alembic migration adding `unavailable_at` column to both market tables:

```sql
ALTER TABLE market_odds
ADD COLUMN unavailable_at TIMESTAMP WITH TIME ZONE;

ALTER TABLE competitor_market_odds
ADD COLUMN unavailable_at TIMESTAMP WITH TIME ZONE;
```

Update ORM models:

1. In `src/db/models/odds.py` - MarketOdds class:
   - Add: `unavailable_at: Mapped[datetime | None] = mapped_column(DateTime(timezone=True), nullable=True)`

2. In `src/db/models/competitor.py` - CompetitorMarketOdds class:
   - Add: `unavailable_at: Mapped[datetime | None] = mapped_column(DateTime(timezone=True), nullable=True)`

No backfill needed - existing data defaults to NULL (available).
  </action>
  <verify>
alembic upgrade head completes without errors
python -c "from src.db.models.odds import MarketOdds; print(hasattr(MarketOdds, 'unavailable_at'))"
python -c "from src.db.models.competitor import CompetitorMarketOdds; print(hasattr(CompetitorMarketOdds, 'unavailable_at'))"
  </verify>
  <done>Migration applied, both ORM models have unavailable_at column</done>
</task>

<task type="auto">
  <name>Task 2: CachedMarket Dataclass + Converter Updates</name>
  <files>src/caching/odds_cache.py, src/storage/write_queue.py</files>
  <action>
Update CachedMarket frozen dataclass to track availability:

1. In `src/caching/odds_cache.py` - CachedMarket class:
   - Add field: `unavailable_at: datetime | None = None` (use field() for frozen dataclass default)
   - Actually, since frozen=True, add as last positional field with None default

2. Add property for convenience:
   ```python
   @property
   def is_available(self) -> bool:
       return self.unavailable_at is None
   ```

3. Search for converter functions that create CachedMarket instances:
   - `snapshot_to_cached_from_models()` in write_queue.py or similar
   - `snapshot_to_cached_from_data()` for DTO conversion
   - Update all to pass `unavailable_at` from source (or None if not present)

4. Ensure backward compatibility: existing code creating CachedMarket without unavailable_at should still work (default None).

Do NOT change CachedSnapshot - it contains tuple of CachedMarket, no changes needed.
  </action>
  <verify>
python -c "from src.caching.odds_cache import CachedMarket; m = CachedMarket('1', 'Test', None, None, None, None, [], None, None); print(m.is_available)"
Check that existing tests still pass: pytest src/caching/ -v
  </verify>
  <done>CachedMarket has unavailable_at field with is_available property, converters updated</done>
</task>

<task type="auto">
  <name>Task 3: Availability Detection Module + EventCoordinator Integration</name>
  <files>src/caching/availability_detection.py (new), src/caching/__init__.py, src/scraping/event_coordinator.py</files>
  <action>
Create new module `src/caching/availability_detection.py`:

```python
"""Availability detection for market tracking.

Compares cached market data against newly scraped markets to detect
when markets become unavailable (disappeared from bookmaker) or return
(were unavailable, now available again).

Functions:
    get_market_key(): Generate unique key for market comparison
    detect_availability_changes(): Compare previous cache to new scrape
"""

from __future__ import annotations
from dataclasses import replace
from datetime import datetime
from typing import Any

import structlog

from src.caching.odds_cache import CachedMarket

logger = structlog.get_logger(__name__)


def get_market_key(market: CachedMarket | dict[str, Any]) -> tuple[str, float | None]:
    """Generate unique key for market comparison.

    Args:
        market: CachedMarket instance or dict with betpawa_market_id and line

    Returns:
        Tuple of (betpawa_market_id, line) for dictionary lookup
    """
    if isinstance(market, CachedMarket):
        return (market.betpawa_market_id, market.line)
    return (str(market.get("betpawa_market_id", "")), market.get("line"))


def detect_availability_changes(
    previous_markets: dict[tuple[str, float | None], CachedMarket],
    new_market_data: list[Any],
    timestamp: datetime,
) -> tuple[list[CachedMarket], list[CachedMarket], list[tuple[str, float | None]]]:
    """Compare previous cache state to new scrape results.

    Detects:
    - Markets that disappeared (were available, now missing)
    - Markets that returned (were unavailable, now present)

    Args:
        previous_markets: Dict of market_key -> CachedMarket from cache
        new_market_data: List of newly scraped market objects (ORM or dict)
        timestamp: Current timestamp for unavailable_at

    Returns:
        Tuple of:
        - became_unavailable: CachedMarket instances with unavailable_at set
        - became_available: CachedMarket instances with unavailable_at cleared
        - disappeared_keys: Market keys that disappeared (for logging)
    """
    # Build set of keys from new scrape
    new_keys: set[tuple[str, float | None]] = set()
    for m in new_market_data:
        if isinstance(m, dict):
            key = (str(m.get("betpawa_market_id", "")), m.get("line"))
        else:
            key = (str(m.betpawa_market_id), m.line)
        new_keys.add(key)

    previous_keys = set(previous_markets.keys())

    # Markets that were available but are now missing
    disappeared_keys = previous_keys - new_keys

    # Markets that are in new scrape
    present_keys = new_keys & previous_keys

    became_unavailable: list[CachedMarket] = []
    became_available: list[CachedMarket] = []

    # Check disappeared markets
    for key in disappeared_keys:
        prev = previous_markets[key]
        if prev.unavailable_at is None:  # Was available, now gone
            # Create updated market with unavailable_at set
            became_unavailable.append(replace(prev, unavailable_at=timestamp))

    # Check present markets that were previously unavailable
    for key in present_keys:
        prev = previous_markets[key]
        if prev.unavailable_at is not None:  # Was unavailable, now back
            # Create updated market with unavailable_at cleared
            became_available.append(replace(prev, unavailable_at=None))

    if became_unavailable or became_available:
        logger.info(
            "availability_detection.changes",
            became_unavailable=len(became_unavailable),
            became_available=len(became_available),
            disappeared_keys_count=len(disappeared_keys),
        )

    return became_unavailable, became_available, list(disappeared_keys)
```

Update `src/caching/__init__.py` to export:
```python
from src.caching.availability_detection import (
    get_market_key,
    detect_availability_changes,
)
```

Integrate into EventCoordinator:

In `src/scraping/event_coordinator.py`, after change detection in `store_batch_results()`:

1. Import the detection function
2. Before updating cache with new data, call `detect_availability_changes()`
3. Update cache to mark unavailable markets
4. Add method `_detect_and_update_availability()` to handle this flow

The integration point is AFTER scraping, BEFORE cache update:
- Get previous markets from cache for this event
- Compare to new scraped markets
- Update cache entries that changed availability
- Log changes for observability

Note: Phase 89 will handle persisting availability to DB during snapshot creation. Phase 88 focuses on detection and cache state.
  </action>
  <verify>
python -c "from src.caching.availability_detection import get_market_key, detect_availability_changes; print('imports ok')"
Manual verification: Run scraper cycle, check logs for "availability_detection.changes" entries
  </verify>
  <done>
Availability detection module created, integrated into EventCoordinator, changes logged during scrape cycles
  </done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `alembic upgrade head` succeeds
- [ ] `alembic downgrade -1` and `alembic upgrade head` work (reversible)
- [ ] CachedMarket instances can be created with unavailable_at field
- [ ] Availability detection function correctly identifies disappeared markets
- [ ] EventCoordinator logs availability changes during scrape cycle
- [ ] No TypeScript/Python errors introduced
- [ ] Existing tests pass
</verification>

<success_criteria>

- Schema migration applied with unavailable_at column on both market tables
- CachedMarket has unavailable_at field and is_available property
- Availability detection module created with get_market_key and detect_availability_changes
- EventCoordinator calls detection logic during scrape cycle
- Changes logged to structlog for observability
- No regressions in existing scraping functionality
</success_criteria>

<output>
After completion, create `.planning/phases/88-backend-availability-tracking/88-01-SUMMARY.md`:

# Phase 88 Plan 01: Backend Availability Tracking Summary

**[One-liner describing what was implemented]**

## Accomplishments

- [Migration created and applied]
- [CachedMarket updated]
- [Detection module created]
- [Integration completed]

## Files Created/Modified

- `alembic/versions/xxxx_add_unavailable_at.py` - Schema migration
- `src/db/models/odds.py` - MarketOdds.unavailable_at
- `src/db/models/competitor.py` - CompetitorMarketOdds.unavailable_at
- `src/caching/odds_cache.py` - CachedMarket.unavailable_at
- `src/caching/availability_detection.py` - New detection module
- `src/caching/__init__.py` - Exports
- `src/scraping/event_coordinator.py` - Integration

## Decisions Made

[Key decisions and rationale]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

- Phase 89 can now add availability to API responses
- Cache tracks availability state for API consumption
</output>
