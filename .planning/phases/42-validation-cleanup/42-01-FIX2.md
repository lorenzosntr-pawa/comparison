---
phase: 42-validation-cleanup
plan: 01-FIX2
type: fix
---

<objective>
Fix 1 blocker UAT issue from plan 42-01-FIX: BetPawa discovers 155 competitions but 0 events.

Source: 42-01-FIX-ISSUES.md
Priority: 1 blocker

**Root cause identified:** Two architectural mismatches between old orchestrator and new EventCoordinator:
1. Wrong response keys: `eventLists[].events[]` vs actual `responses[0].responses[]`
2. Missing full event fetch step to get SR IDs from widgets array
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md

**Issues being fixed:**
@.planning/phases/42-validation-cleanup/42-01-FIX-ISSUES.md

**Key source file:**
@src/scraping/event_coordinator.py

**Reference - Old orchestrator BetPawa code (from git history):**
The old `_scrape_betpawa_competition` method used this pattern:
```python
# 1. Parse response structure
responses = events_response.get("responses", [])
first_response = responses[0]
events_data = first_response.get("responses", [])

# 2. Parse minimal event data (BetPawa ID, basic info)
for event_data in events_data:
    parsed = self._parse_betpawa_event(event_data)  # Gets BetPawa event ID

# 3. Fetch FULL event details (including widgets with SR ID)
full_event_data = await client.fetch_event(event_id)

# 4. Extract SR ID from widgets array in FULL response
widgets = full_event_data.get("widgets", [])
for widget in widgets:
    if widget.get("type") == "SPORTRADAR":
        sportradar_id = widget.get("id")
```

**Key insight:** The events list response does NOT contain the widgets array. Only the full event response (fetch_event) has it.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix event list response parsing</name>
  <files>src/scraping/event_coordinator.py</files>
  <action>
In `_discover_betpawa` method (around line 263-291), fix the event list response parsing:

**Current (broken):**
```python
event_lists = data.get("eventLists", [])
for event_list in event_lists:
    for event_data in event_list.get("events", []):
```

**Change to (matching old orchestrator):**
```python
responses = data.get("responses", [])
if not responses:
    return []
first_response = responses[0]
events_data = first_response.get("responses", [])
for event_data in events_data:
```

Add debug logging to verify the fix:
```python
logger.info(
    "BetPawa events response structure",
    response_keys=list(data.keys()),
    responses_count=len(responses) if responses else 0,
)
```
  </action>
  <verify>
1. Trigger a scrape
2. Check logs for "BetPawa events response structure" showing responses_count > 0
3. This alone won't give SR IDs yet (Task 2 needed), but should show events being found
  </verify>
  <done>
- Response parsing uses correct keys: `responses[0].responses`
- Logging shows events being found from competitions
  </done>
</task>

<task type="auto">
  <name>Task 2: Add full event fetch step for SR IDs</name>
  <files>src/scraping/event_coordinator.py</files>
  <action>
The events list response has minimal data (BetPawa event ID, teams, kickoff) but NOT the widgets array with SR ID. We need a second pass to fetch full event details.

**Modify `_discover_betpawa` to add full event fetch step:**

After parsing events from list response:
1. Extract BetPawa event IDs from the list response
2. Use semaphore-limited parallel fetches to get full event details
3. Extract SR ID from widgets array in full response

**Implementation pattern (from old orchestrator):**
```python
async def fetch_comp_events(comp_id: str) -> list[dict]:
    async with semaphore:
        try:
            data = await client.fetch_events(comp_id)

            # Parse list response (correct structure)
            responses = data.get("responses", [])
            if not responses:
                return []
            first_response = responses[0]
            events_data = first_response.get("responses", [])

            # Collect BetPawa event IDs from list
            betpawa_event_ids: list[tuple[str, datetime]] = []
            for event_data in events_data:
                event_id = str(event_data.get("id", ""))
                start_time = event_data.get("startTime")
                if event_id and start_time:
                    try:
                        kickoff = datetime.fromisoformat(start_time.replace("Z", "+00:00"))
                        if kickoff > now:  # Filter started events
                            betpawa_event_ids.append((event_id, kickoff))
                    except (ValueError, TypeError):
                        pass

            if not betpawa_event_ids:
                return []

            # Fetch full details (with SR ID) using nested semaphore
            event_semaphore = asyncio.Semaphore(10)

            async def fetch_full_event(event_id: str, kickoff: datetime) -> dict | None:
                async with event_semaphore:
                    try:
                        full_data = await client.fetch_event(event_id)
                        # Extract SR ID from widgets
                        widgets = full_data.get("widgets", [])
                        sr_id = None
                        for widget in widgets:
                            if widget.get("type") == "SPORTRADAR":
                                widget_data = widget.get("data", {})
                                sr_id = str(widget_data.get("matchId", ""))
                                break

                        if sr_id:
                            return {
                                "sr_id": sr_id,
                                "kickoff": kickoff,
                                "platform_id": event_id,
                            }
                    except Exception as e:
                        logger.debug("Failed to fetch BetPawa event", event_id=event_id, error=str(e))
                    return None

            results = await asyncio.gather(
                *[fetch_full_event(eid, ko) for eid, ko in betpawa_event_ids],
                return_exceptions=True,
            )

            return [r for r in results if r is not None and not isinstance(r, Exception)]

        except Exception as e:
            logger.debug("Failed to fetch BetPawa competition", competition_id=comp_id, error=str(e))
            return []
```

**Key changes:**
1. Parse list response with correct keys (`responses[0].responses`)
2. Extract BetPawa event IDs and kickoff times from list
3. Fetch full event details for each (semaphore limited to 10 concurrent)
4. Extract SR ID from widgets array in full response
5. Return events with sr_id, kickoff, and platform_id

Remove the old `_parse_betpawa_event` method call since we're integrating the logic directly.
  </action>
  <verify>
1. Trigger a scrape
2. Check logs for:
   - "Found BetPawa competitions count=155"
   - "Discovered BetPawa events count=XXX" (should be > 0)
3. Event discovery complete should show betpawa > 0
  </verify>
  <done>
- BetPawa events discovered (betpawa > 0 in discovery complete log)
- SR IDs extracted from widgets array
- Events appear in merged event map
  </done>
</task>

<task type="auto">
  <name>Task 3: Clean up unused _parse_betpawa_event method</name>
  <files>src/scraping/event_coordinator.py</files>
  <action>
After integrating the full event fetch logic into `_discover_betpawa`, the `_parse_betpawa_event` method (lines 301-348) is no longer needed for discovery.

However, it MAY still be needed for parsing full event responses during scraping (in `_scrape_event_all_platforms`). Check if it's used elsewhere:
1. Search for `_parse_betpawa_event` usage in the file
2. If only used in discovery (now replaced), remove the method
3. If used elsewhere, keep it

If removing: Delete the entire method (lines 301-348 approximately).

Add a comment explaining the BetPawa discovery flow:
```python
# BetPawa discovery flow:
# 1. fetch_categories() -> competition IDs
# 2. fetch_events(comp_id) -> BetPawa event IDs (list response)
# 3. fetch_event(event_id) -> full event with widgets (SR ID)
```
  </action>
  <verify>
1. Run: `grep -n "_parse_betpawa_event" src/scraping/event_coordinator.py`
2. Should show 0 results (method removed) OR only the method definition if kept for other use
3. Build/import succeeds: `python -c "from src.scraping.event_coordinator import EventCoordinator"`
  </verify>
  <done>
- Unused code removed (if applicable)
- Code is clean with clear comments
- No import/syntax errors
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] UAT-001: BetPawa events discovered (betpawa > 0 in logs)
- [ ] Response parsing uses correct keys (`responses[0].responses`)
- [ ] Full event fetch step added to get SR IDs
- [ ] Full scrape completes with BetPawa events
- [ ] No errors during BetPawa discovery
</verification>

<success_criteria>
- BetPawa discovery returns > 0 events
- Events have valid SR IDs for cross-platform matching
- Scrape shows BetPawa in merged event counts
- Ready for re-verification with /gsd:verify-work
</success_criteria>

<output>
After completion, create `.planning/phases/42-validation-cleanup/42-01-FIX2-SUMMARY.md`

Update 42-01-FIX-ISSUES.md to move UAT-001 to "Resolved Issues" section.
</output>
